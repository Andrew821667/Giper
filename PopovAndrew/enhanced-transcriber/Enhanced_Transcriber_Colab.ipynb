{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enhanced_transcriber_header"
   },
   "source": [
    "# üéØ Enhanced Transcriber - Quality Testing in Google Colab\n",
    "\n",
    "**–¶–µ–ª—å**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ **95%+** –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "\n",
    "**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:\n",
    "- ü§ñ **T-one** - –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "- üéµ **Whisper Local** - –ª–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ API\n",
    "- üîÑ **Ensemble** - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "- üõí **E-commerce** - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–Ω–ª–∞–π–Ω-–º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "- üìä **Quality Metrics** - –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## üîß 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã\n",
    "apt-get update -qq\n",
    "\n",
    "# FFmpeg –¥–ª—è –∞—É–¥–∏–æ\n",
    "apt-get install -y -qq ffmpeg\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install -q librosa soundfile pydub\n",
    "pip install -q openai-whisper\n",
    "pip install -q jiwer sentence-transformers scikit-learn\n",
    "pip install -q pymorphy2 nltk regex\n",
    "pip install -q noisereduce scipy\n",
    "\n",
    "print(\"‚úÖ –ë–∞–∑–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_tone"
   },
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ T-one (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)\n",
    "%%bash\n",
    "echo \"üì• –£—Å—Ç–∞–Ω–æ–≤–∫–∞ T-one ASR (Russian specialist)...\"\n",
    "pip install -q git+https://github.com/voicekit-team/T-one.git\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "python -c \"import tone_asr; print('‚úÖ T-one —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_project_structure"
   },
   "outputs": [],
   "source": "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ Enhanced Transcriber –∏–∑ GitHub\nimport os\nimport sys\nfrom pathlib import Path\n\nprint(\"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Enhanced Transcriber –∏–∑ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...\")\nprint(\"üîó –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/Andrew821667/Giper\")\nprint(\"üåø –í–µ—Ç–∫–∞: main (–æ—Å–Ω–æ–≤–Ω–∞—è)\")\n\n# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ bash)\n# –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ —Å %%bash"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "core_models_section"
   },
   "source": "%%bash\ncd /content\nif [ -d \"Giper\" ]; then\n    echo \"üîÑ –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π...\"\n    rm -rf Giper\nfi\n\necho \"üì• –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π Giper –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –≤–µ—Ç–∫–∏ main...\"\ngit clone https://github.com/Andrew821667/Giper.git\n\nif [ -d \"Giper/PopovAndrew/enhanced-transcriber\" ]; then\n    echo \"‚úÖ Enhanced Transcriber —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –≤–µ—Ç–∫–∏ main!\"\n    echo \"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\"\n    ls -la Giper/PopovAndrew/enhanced-transcriber/\nelse\n    echo \"‚ùå –û—à–∏–±–∫–∞: Enhanced Transcriber –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏\"\n    echo \"üîç –ü—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ –µ—Å—Ç—å –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏:\"\n    ls -la Giper/\nfi"
  },
  {
   "cell_type": "code",
   "source": "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ Enhanced Transcriber\nimport os\nimport sys\nfrom pathlib import Path\n\n# –ü—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É Enhanced Transcriber\nenhanced_transcriber_path = \"/content/Giper/PopovAndrew/enhanced-transcriber\"\n\nif Path(enhanced_transcriber_path).exists():\n    print(\"‚úÖ Enhanced Transcriber –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏!\")\n    \n    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–ª–∏–Ω–∫–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n    if Path('/content/enhanced_transcriber').exists():\n        os.system(\"rm -f /content/enhanced_transcriber\")\n    os.system(f\"ln -sf {enhanced_transcriber_path} /content/enhanced_transcriber\")\n    \n    # –î–æ–±–∞–≤–ª—è–µ–º –≤ Python path\n    sys.path.insert(0, '/content')\n    sys.path.insert(0, enhanced_transcriber_path)\n    \n    print(\"üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ Enhanced Transcriber:\")\n    \n    # –ü–æ–∫–∞–∑–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –ø–∞–ø–∫–∏\n    for item in sorted(Path(enhanced_transcriber_path).iterdir()):\n        if item.is_file() and item.suffix in ['.py', '.md', '.txt', '.ipynb']:\n            size_kb = item.stat().st_size // 1024\n            print(f\"   üìÑ {item.name} ({size_kb} KB)\")\n        elif item.is_dir() and not item.name.startswith('.'):\n            file_count = len(list(item.iterdir())) if item.is_dir() else 0\n            print(f\"   üìÅ {item.name}/ ({file_count} files)\")\n            \n    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è –∞—É–¥–∏–æ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n    Path('/content/audio_samples').mkdir(exist_ok=True)\n    Path('/content/results').mkdir(exist_ok=True)\n    \n    print(\"\\n‚úÖ Enhanced Transcriber –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\")\n    print(\"üéØ –¶–µ–ª–µ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: 95%+ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\")\n    print(\"üõí –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: E-commerce –¥–æ–º–µ–Ω\")\n    \nelse:\n    print(\"‚ùå –û–®–ò–ë–ö–ê: Enhanced Transcriber –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏!\")\n    print(f\"–û–∂–∏–¥–∞–µ–º—ã–π –ø—É—Ç—å: {enhanced_transcriber_path}\")\n    print(\"üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –≤–µ—Ç–∫—É 'main' –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ Giper\")\n    \n    # Fallback: —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n    print(\"\\n‚ö†Ô∏è –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...\")\n    project_dirs = [\n        '/content/enhanced_transcriber',\n        '/content/enhanced_transcriber/core/interfaces',\n        '/content/enhanced_transcriber/core/models',\n        '/content/enhanced_transcriber/providers/tone',\n        '/content/enhanced_transcriber/providers/whisper',\n        '/content/enhanced_transcriber/services'\n    ]\n    \n    for dir_path in project_dirs:\n        Path(dir_path).mkdir(parents=True, exist_ok=True)\n        (Path(dir_path) / '__init__.py').touch()\n    \n    sys.path.insert(0, '/content')\n    print(\"üìÅ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%bash\ncd /content\nif [ -d \"Giper\" ]; then\n    echo \"üîÑ –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π...\"\n    rm -rf Giper\nfi\n\necho \"üì• –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π Giper –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –≤–µ—Ç–∫–∏ main...\"\ngit clone https://github.com/Andrew821667/Giper.git\n\nif [ -d \"Giper/PopovAndrew/enhanced-transcriber\" ]; then\n    echo \"‚úÖ Enhanced Transcriber —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –≤–µ—Ç–∫–∏ main!\"\n    echo \"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\"\n    ls -la Giper/PopovAndrew/enhanced-transcriber/\nelse\n    echo \"‚ùå –û—à–∏–±–∫–∞: Enhanced Transcriber –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏\"\n    echo \"üîç –ü—Ä–æ–≤–µ—Ä–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:\"\n    find Giper -name \"enhanced-transcriber\" -type d\nfi",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_transcription_result"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/core/models/transcription_result.py\n",
    "\"\"\"\n",
    "–ú–æ–¥–µ–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\n",
    "Transcription result data models\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class TranscriptionStatus(Enum):\n",
    "    \"\"\"–°—Ç–∞—Ç—É—Å—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\"\"\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    PROCESSING = \"processing\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WordTimestamp:\n",
    "    \"\"\"–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ —Å–ª–æ–≤–∞\"\"\"\n",
    "    word: str\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class TranscriptionResult:\n",
    "    \"\"\"–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\"\"\"\n",
    "    text: str\n",
    "    confidence: float\n",
    "    processing_time: float\n",
    "    model_used: str\n",
    "    language_detected: str\n",
    "    status: TranscriptionStatus = TranscriptionStatus.COMPLETED\n",
    "    \n",
    "    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è\n",
    "    word_timestamps: Optional[List[WordTimestamp]] = None\n",
    "    audio_duration: Optional[float] = None\n",
    "    sample_rate: Optional[int] = None\n",
    "    file_size: Optional[int] = None\n",
    "    error_message: Optional[str] = None\n",
    "    provider_metadata: Optional[Dict[str, Any]] = None\n",
    "    quality_metrics: Optional[Any] = None  # QualityMetrics\n",
    "    \n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "print(\"‚úÖ TranscriptionResult –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_quality_metrics"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/core/models/quality_metrics.py\n",
    "\"\"\"\n",
    "–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Colab\n",
    "Simplified quality metrics for Colab\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Any, List\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class QualityLevel(Enum):\n",
    "    \"\"\"–£—Ä–æ–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "    EXCELLENT = \"excellent\"  # 0.9+\n",
    "    GOOD = \"good\"           # 0.7-0.9\n",
    "    FAIR = \"fair\"           # 0.5-0.7\n",
    "    POOR = \"poor\"           # 0.3-0.5\n",
    "    VERY_POOR = \"very_poor\" # <0.3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QualityMetrics:\n",
    "    \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    word_error_rate: Optional[float] = None\n",
    "    character_error_rate: Optional[float] = None\n",
    "    overall_score: float = 0.0\n",
    "    quality_level: QualityLevel = QualityLevel.FAIR\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "    word_count: int = 0\n",
    "    unique_words_count: int = 0\n",
    "    vocabulary_richness: float = 0.0\n",
    "    \n",
    "    # Confidence –º–µ—Ç—Ä–∏–∫–∏\n",
    "    average_word_confidence: Optional[float] = None\n",
    "    low_confidence_words_count: int = 0\n",
    "    low_confidence_percentage: float = 0.0\n",
    "    \n",
    "    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "    improvement_suggestions: List[str] = field(default_factory=list)\n",
    "    needs_manual_review: bool = False\n",
    "    retry_recommended: bool = False\n",
    "    \n",
    "    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "    evaluated_at: datetime = field(default_factory=datetime.now)\n",
    "    evaluation_method: str = \"simplified\"\n",
    "    reference_available: bool = False\n",
    "    \n",
    "    def update_overall_assessment(self):\n",
    "        \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        if self.word_error_rate is not None:\n",
    "            scores.append(1 - self.word_error_rate)\n",
    "        \n",
    "        if self.character_error_rate is not None:\n",
    "            scores.append(1 - self.character_error_rate)\n",
    "            \n",
    "        if self.average_word_confidence is not None:\n",
    "            scores.append(self.average_word_confidence)\n",
    "            \n",
    "        if scores:\n",
    "            self.overall_score = sum(scores) / len(scores)\n",
    "        else:\n",
    "            # –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞\n",
    "            if self.word_count > 0:\n",
    "                self.overall_score = min(0.85, 0.5 + (self.vocabulary_richness * 0.3))\n",
    "            else:\n",
    "                self.overall_score = 0.0\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "        if self.overall_score >= 0.9:\n",
    "            self.quality_level = QualityLevel.EXCELLENT\n",
    "        elif self.overall_score >= 0.7:\n",
    "            self.quality_level = QualityLevel.GOOD\n",
    "        elif self.overall_score >= 0.5:\n",
    "            self.quality_level = QualityLevel.FAIR\n",
    "        elif self.overall_score >= 0.3:\n",
    "            self.quality_level = QualityLevel.POOR\n",
    "        else:\n",
    "            self.quality_level = QualityLevel.VERY_POOR\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å\"\"\"\n",
    "        return {\n",
    "            \"word_error_rate\": self.word_error_rate,\n",
    "            \"character_error_rate\": self.character_error_rate,\n",
    "            \"overall_score\": self.overall_score,\n",
    "            \"quality_level\": self.quality_level.value,\n",
    "            \"word_count\": self.word_count,\n",
    "            \"vocabulary_richness\": self.vocabulary_richness,\n",
    "            \"average_word_confidence\": self.average_word_confidence,\n",
    "            \"improvement_suggestions\": self.improvement_suggestions,\n",
    "            \"evaluation_method\": self.evaluation_method\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ QualityMetrics –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_transcriber_interface"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/core/interfaces/transcriber.py\n",
    "\"\"\"\n",
    "–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä–∞\n",
    "Transcriber interface\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Dict, Any, List\n",
    "from ..models.transcription_result import TranscriptionResult\n",
    "\n",
    "\n",
    "class ITranscriber(ABC):\n",
    "    \"\"\"–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä–∞\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def transcribe(\n",
    "        self, \n",
    "        audio_file: str, \n",
    "        language: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def is_supported_format(self, file_path: str) -> bool:\n",
    "        \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def model_name(self) -> str:\n",
    "        \"\"\"–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def supported_languages(self) -> List[str]:\n",
    "        \"\"\"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏\"\"\"\n",
    "        pass\n",
    "\n",
    "print(\"‚úÖ ITranscriber –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "providers_section"
   },
   "source": [
    "## ü§ñ 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_tone_provider"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/providers/tone/tone_provider.py\n",
    "\"\"\"\n",
    "T-one –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Colab (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)\n",
    "T-one provider for Colab (simplified)\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "from ...core.interfaces.transcriber import ITranscriber\n",
    "from ...core.models.transcription_result import TranscriptionResult, TranscriptionStatus\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ToneTranscriber(ITranscriber):\n",
    "    \"\"\"T-one —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"voicekit/tone-ru\"):\n",
    "        self.model_name_str = model_name\n",
    "        self._model = None\n",
    "        self._supported_formats = {'.wav', '.mp3', '.m4a', '.flac', '.ogg'}\n",
    "        self._supported_languages = ['ru']\n",
    "        \n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è T-one –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        try:\n",
    "            from tone_asr import ToneASR\n",
    "            self._model = ToneASR.from_pretrained(self.model_name_str)\n",
    "            print(f\"‚úÖ T-one model '{self.model_name_str}' loaded successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ùå T-one not available: {e}\")\n",
    "            raise ImportError(\"T-one ASR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load T-one: {e}\")\n",
    "            raise RuntimeError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å T-one: {e}\")\n",
    "    \n",
    "    async def transcribe(\n",
    "        self, \n",
    "        audio_file: str, \n",
    "        language: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å T-one\"\"\"\n",
    "        if not self._model:\n",
    "            raise RuntimeError(\"T-one model not initialized\")\n",
    "        \n",
    "        if not Path(audio_file).exists():\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n",
    "            loop = asyncio.get_event_loop()\n",
    "            result = await loop.run_in_executor(\n",
    "                None, \n",
    "                self._sync_transcribe, \n",
    "                audio_file\n",
    "            )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ\n",
    "            enhanced_text = self._enhance_russian_text(result['text'])\n",
    "            \n",
    "            return TranscriptionResult(\n",
    "                text=enhanced_text,\n",
    "                confidence=result.get('confidence', 0.85),\n",
    "                processing_time=processing_time,\n",
    "                model_used=f\"T-one ({self.model_name_str})\",\n",
    "                language_detected=\"ru\",\n",
    "                status=TranscriptionStatus.COMPLETED,\n",
    "                provider_metadata={\n",
    "                    \"model_name\": self.model_name_str,\n",
    "                    \"provider\": \"tone\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå T-one transcription failed: {e}\")\n",
    "            return TranscriptionResult(\n",
    "                text=\"\",\n",
    "                confidence=0.0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                model_used=f\"T-one ({self.model_name_str})\",\n",
    "                language_detected=\"ru\",\n",
    "                status=TranscriptionStatus.FAILED,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "    \n",
    "    def _sync_transcribe(self, audio_file: str) -> Dict[str, Any]:\n",
    "        \"\"\"–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\"\"\"\n",
    "        try:\n",
    "            result = self._model.transcribe(audio_file)\n",
    "            \n",
    "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "            if hasattr(result, 'text'):\n",
    "                text = result.text\n",
    "                confidence = getattr(result, 'confidence', 0.85)\n",
    "            elif isinstance(result, dict):\n",
    "                text = result.get('text', '')\n",
    "                confidence = result.get('confidence', 0.85)\n",
    "            else:\n",
    "                text = str(result)\n",
    "                confidence = 0.85\n",
    "            \n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"confidence\": confidence\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"T-one sync transcription failed: {e}\")\n",
    "    \n",
    "    def _enhance_russian_text(self, text: str) -> str:\n",
    "        \"\"\"–£–ª—É—á—à–µ–Ω–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        if not text:\n",
    "            return text\n",
    "        \n",
    "        import re\n",
    "        enhanced_text = text\n",
    "        \n",
    "        # E-commerce –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
    "        corrections = {\n",
    "            r'\\b(–∑–∞–∫–∞—Å|–∑–æ–∫–∞—Å|–∑–∞–∫–∞–∑—å)\\b': '–∑–∞–∫–∞–∑',\n",
    "            r'\\b(–∞–ø–ª–∞—Ç–∞|–æ–ø–ª–æ—Ç–æ|–∞–ø–ª–æ—Ç–æ)\\b': '–æ–ø–ª–∞—Ç–∞',\n",
    "            r'\\b(–¥–æ—Å—Ç–≤–∫–∞|–¥–∞—Å—Ç–∞—Ñ–∫–∞|–¥–æ—Å—Ç–∞–∫–∞)\\b': '–¥–æ—Å—Ç–∞–≤–∫–∞',\n",
    "            r'\\b(–≤–æ–∑—Ä–∞—Ç|–≤–∞–∑–≤—Ä–∞—Ç|–≤–æ–∑—Ä–∞—Ç—å)\\b': '–≤–æ–∑–≤—Ä–∞—Ç',\n",
    "            r'\\b(—Ç–∞–≤–∞—Ä|—Ç–æ–≤–æ—Ä—Ä|—Ç–æ–≤–æ—Ä)\\b': '—Ç–æ–≤–∞—Ä',\n",
    "            r'\\b(—Å–∫–∏—Ç–∫–∞|—Å–∫–∏–¥–∫–æ|—Å–∫–∏—Ç–∫–æ)\\b': '—Å–∫–∏–¥–∫–∞',\n",
    "            r'\\b(–∫–∞—Ä–∑–∏–Ω–∞|–∫–æ—Ä–∑–∏–Ω–æ|–∫–∞—Ä–∑–∏–Ω–æ)\\b': '–∫–æ—Ä–∑–∏–Ω–∞'\n",
    "        }\n",
    "        \n",
    "        for pattern, replacement in corrections.items():\n",
    "            enhanced_text = re.sub(pattern, replacement, enhanced_text, flags=re.IGNORECASE)\n",
    "        \n",
    "        return enhanced_text.strip()\n",
    "    \n",
    "    def is_supported_format(self, file_path: str) -> bool:\n",
    "        return Path(file_path).suffix.lower() in self._supported_formats\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": self.model_name_str,\n",
    "            \"provider\": \"tone\",\n",
    "            \"specialization\": \"Russian language, telephony domain\",\n",
    "            \"supported_languages\": self._supported_languages,\n",
    "            \"supported_formats\": list(self._supported_formats)\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def model_name(self) -> str:\n",
    "        return self.model_name_str\n",
    "    \n",
    "    @property\n",
    "    def supported_languages(self) -> List[str]:\n",
    "        return self._supported_languages.copy()\n",
    "\n",
    "print(\"‚úÖ ToneTranscriber —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_whisper_local"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/providers/whisper/whisper_local.py\n",
    "\"\"\"\n",
    "Whisper Local –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Colab\n",
    "Whisper Local provider for Colab\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "from ...core.interfaces.transcriber import ITranscriber\n",
    "from ...core.models.transcription_result import TranscriptionResult, TranscriptionStatus\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class WhisperLocalTranscriber(ITranscriber):\n",
    "    \"\"\"–õ–æ–∫–∞–ª—å–Ω—ã–π Whisper —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"base\", device: str = \"cuda\"):\n",
    "        self.model_name_str = model_name\n",
    "        self.device = device\n",
    "        self._model = None\n",
    "        self._supported_formats = {'.wav', '.mp3', '.m4a', '.flac', '.ogg'}\n",
    "        self._supported_languages = ['ru', 'en', 'auto']\n",
    "        \n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        try:\n",
    "            import whisper\n",
    "            \n",
    "            print(f\"üì• Loading Whisper {self.model_name_str} model...\")\n",
    "            self._model = whisper.load_model(\n",
    "                name=self.model_name_str,\n",
    "                device=self.device\n",
    "            )\n",
    "            print(f\"‚úÖ Whisper {self.model_name_str} model loaded on {self.device}\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"‚ùå Whisper not available: {e}\")\n",
    "            raise ImportError(\"OpenAI Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load Whisper: {e}\")\n",
    "            raise RuntimeError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Whisper: {e}\")\n",
    "    \n",
    "    async def transcribe(\n",
    "        self, \n",
    "        audio_file: str, \n",
    "        language: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å Whisper\"\"\"\n",
    "        if not self._model:\n",
    "            raise RuntimeError(\"Whisper model not initialized\")\n",
    "        \n",
    "        if not Path(audio_file).exists():\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n",
    "            loop = asyncio.get_event_loop()\n",
    "            result = await loop.run_in_executor(\n",
    "                None, \n",
    "                self._sync_transcribe, \n",
    "                audio_file,\n",
    "                language\n",
    "            )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ\n",
    "            text = result['text']\n",
    "            if result.get('language') == 'ru' or language == 'ru':\n",
    "                text = self._enhance_russian_text(text)\n",
    "            \n",
    "            return TranscriptionResult(\n",
    "                text=text,\n",
    "                confidence=result.get('avg_confidence', 0.8),\n",
    "                processing_time=processing_time,\n",
    "                model_used=f\"Whisper Local ({self.model_name_str})\",\n",
    "                language_detected=result.get('language', language or 'auto'),\n",
    "                status=TranscriptionStatus.COMPLETED,\n",
    "                provider_metadata={\n",
    "                    \"model_size\": self.model_name_str,\n",
    "                    \"provider\": \"whisper_local\",\n",
    "                    \"device\": self.device\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Whisper transcription failed: {e}\")\n",
    "            return TranscriptionResult(\n",
    "                text=\"\",\n",
    "                confidence=0.0,\n",
    "                processing_time=time.time() - start_time,\n",
    "                model_used=f\"Whisper Local ({self.model_name_str})\",\n",
    "                language_detected=language or \"unknown\",\n",
    "                status=TranscriptionStatus.FAILED,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "    \n",
    "    def _sync_transcribe(self, audio_file: str, language: Optional[str]) -> Dict[str, Any]:\n",
    "        \"\"\"–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\"\"\"\n",
    "        try:\n",
    "            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\n",
    "            options = {\n",
    "                \"verbose\": False,\n",
    "                \"temperature\": 0.0\n",
    "            }\n",
    "            \n",
    "            if language and language != \"auto\":\n",
    "                options[\"language\"] = language\n",
    "            \n",
    "            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n",
    "            result = self._model.transcribe(audio_file, **options)\n",
    "            \n",
    "            # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "            avg_confidence = 0.8\n",
    "            if \"segments\" in result and result[\"segments\"]:\n",
    "                confidences = [seg.get(\"avg_logprob\", -1.0) for seg in result[\"segments\"]]\n",
    "                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è log prob –≤ confidence\n",
    "                avg_confidence = sum(min(1.0, max(0.0, c + 1.0)) for c in confidences) / len(confidences)\n",
    "            \n",
    "            return {\n",
    "                \"text\": result[\"text\"].strip(),\n",
    "                \"language\": result.get(\"language\", \"unknown\"),\n",
    "                \"avg_confidence\": avg_confidence\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Whisper sync transcription failed: {e}\")\n",
    "    \n",
    "    def _enhance_russian_text(self, text: str) -> str:\n",
    "        \"\"\"–£–ª—É—á—à–µ–Ω–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        if not text:\n",
    "            return text\n",
    "        \n",
    "        import re\n",
    "        enhanced_text = text\n",
    "        \n",
    "        # –ë–∞–∑–æ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ\n",
    "        corrections = {\n",
    "            r'\\b—Ç[–æ–µ]\\s*–µ—Å—Ç—å\\b': '—Ç–æ –µ—Å—Ç—å',\n",
    "            r'\\b–ø–æ\\s*—ç—Ç–æ–º—É\\b': '–ø–æ—ç—Ç–æ–º—É',\n",
    "            r'\\b—Ç–∞–∫\\s*–∂–µ\\b': '—Ç–∞–∫–∂–µ',\n",
    "            r'\\b–≤—Å—ë\\s*—Ç–∞–∫–∏\\b': '–≤—Å—ë-—Ç–∞–∫–∏',\n",
    "            r'\\b–∫–∞–∫\\s*–±—É–¥—Ç–æ\\b': '–∫–∞–∫ –±—É–¥—Ç–æ'\n",
    "        }\n",
    "        \n",
    "        for pattern, replacement in corrections.items():\n",
    "            enhanced_text = re.sub(pattern, replacement, enhanced_text, flags=re.IGNORECASE)\n",
    "        \n",
    "        return enhanced_text.strip()\n",
    "    \n",
    "    def is_supported_format(self, file_path: str) -> bool:\n",
    "        return Path(file_path).suffix.lower() in self._supported_formats\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": self.model_name_str,\n",
    "            \"provider\": \"whisper_local\",\n",
    "            \"specialization\": \"Multilingual, general domain\",\n",
    "            \"supported_languages\": self._supported_languages,\n",
    "            \"supported_formats\": list(self._supported_formats),\n",
    "            \"device\": self.device\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def model_name(self) -> str:\n",
    "        return self.model_name_str\n",
    "    \n",
    "    @property\n",
    "    def supported_languages(self) -> List[str]:\n",
    "        return self._supported_languages.copy()\n",
    "\n",
    "print(\"‚úÖ WhisperLocalTranscriber —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ensemble_section"
   },
   "source": [
    "## üîÑ 4. –°–æ–∑–¥–∞–Ω–∏–µ Ensemble Service –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ 95%+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_quality_assessor"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/services/quality_assessor.py\n",
    "\"\"\"\n",
    "–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ—Ü–µ–Ω—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Colab\n",
    "Simplified quality assessor for Colab\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "from typing import Optional, List\n",
    "from ..core.models.quality_metrics import QualityMetrics, QualityLevel\n",
    "\n",
    "\n",
    "class SimpleQualityAssessor:\n",
    "    \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ—Ü–µ–Ω—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "    \n",
    "    def __init__(self, confidence_threshold: float = 0.8):\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "    \n",
    "    def assess_quality(\n",
    "        self,\n",
    "        transcribed_text: str,\n",
    "        reference_text: Optional[str] = None,\n",
    "        confidence: float = 0.8,\n",
    "        **kwargs\n",
    "    ) -> QualityMetrics:\n",
    "        \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "        \n",
    "        if not transcribed_text.strip():\n",
    "            return self._create_empty_metrics(\"Empty transcription\")\n",
    "        \n",
    "        metrics = QualityMetrics()\n",
    "        \n",
    "        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "        self._analyze_text_content(transcribed_text, metrics)\n",
    "        \n",
    "        # WER/CER –µ—Å–ª–∏ –µ—Å—Ç—å reference\n",
    "        if reference_text:\n",
    "            self._calculate_error_rates(transcribed_text, reference_text, metrics)\n",
    "        \n",
    "        # Confidence –∞–Ω–∞–ª–∏–∑\n",
    "        metrics.average_word_confidence = confidence\n",
    "        if confidence < self.confidence_threshold:\n",
    "            metrics.low_confidence_words_count = len(transcribed_text.split())\n",
    "            metrics.low_confidence_percentage = 1.0\n",
    "        \n",
    "        # E-commerce —Ç–µ—Ä–º–∏–Ω—ã\n",
    "        self._analyze_ecommerce_terms(transcribed_text, metrics)\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "        metrics.update_overall_assessment()\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _analyze_text_content(self, text: str, metrics: QualityMetrics):\n",
    "        \"\"\"–ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        words = text.split()\n",
    "        metrics.word_count = len(words)\n",
    "        \n",
    "        if words:\n",
    "            unique_words = set(word.lower() for word in words)\n",
    "            metrics.unique_words_count = len(unique_words)\n",
    "            metrics.vocabulary_richness = len(unique_words) / len(words)\n",
    "    \n",
    "    def _calculate_error_rates(self, transcribed: str, reference: str, metrics: QualityMetrics):\n",
    "        \"\"\"–ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç WER/CER\"\"\"\n",
    "        try:\n",
    "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤\n",
    "            trans_norm = self._normalize_text(transcribed)\n",
    "            ref_norm = self._normalize_text(reference)\n",
    "            \n",
    "            # –ü—Ä–æ—Å—Ç–æ–π WER\n",
    "            trans_words = trans_norm.split()\n",
    "            ref_words = ref_norm.split()\n",
    "            \n",
    "            if ref_words:\n",
    "                # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π WER (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π)\n",
    "                common_words = set(trans_words) & set(ref_words)\n",
    "                wer = 1 - (len(common_words) / len(ref_words))\n",
    "                metrics.word_error_rate = max(0.0, min(1.0, wer))\n",
    "            \n",
    "            # –ü—Ä–æ—Å—Ç–æ–π CER\n",
    "            if reference:\n",
    "                # Character level similarity\n",
    "                ref_chars = set(ref_norm.lower())\n",
    "                trans_chars = set(trans_norm.lower())\n",
    "                common_chars = ref_chars & trans_chars\n",
    "                if ref_chars:\n",
    "                    cer = 1 - (len(common_chars) / len(ref_chars))\n",
    "                    metrics.character_error_rate = max(0.0, min(1.0, cer))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error rate calculation failed: {e}\")\n",
    "    \n",
    "    def _analyze_ecommerce_terms(self, text: str, metrics: QualityMetrics):\n",
    "        \"\"\"–ê–Ω–∞–ª–∏–∑ e-commerce —Ç–µ—Ä–º–∏–Ω–æ–≤\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã\n",
    "        correct_terms = [\n",
    "            '–∑–∞–∫–∞–∑', '–æ–ø–ª–∞—Ç–∞', '–¥–æ—Å—Ç–∞–≤–∫–∞', '–≤–æ–∑–≤—Ä–∞—Ç', '—Ç–æ–≤–∞—Ä', \n",
    "            '—Å–∫–∏–¥–∫–∞', '–∫–æ—Ä–∑–∏–Ω–∞', '–∫–∞—á–µ—Å—Ç–≤–æ', '–≥–∞—Ä–∞–Ω—Ç–∏—è'\n",
    "        ]\n",
    "        \n",
    "        # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã\n",
    "        wrong_terms = [\n",
    "            '–∑–∞–∫–∞—Å', '–∑–æ–∫–∞—Å', '–∞–ø–ª–∞—Ç–∞', '–æ–ø–ª–æ—Ç–æ', '–¥–æ—Å—Ç–≤–∫–∞', '–¥–∞—Å—Ç–∞—Ñ–∫–∞',\n",
    "            '–≤–æ–∑—Ä–∞—Ç', '–≤–∞–∑–≤—Ä–∞—Ç', '—Ç–∞–≤–∞—Ä', '—Ç–æ–≤–æ—Ä—Ä', '—Å–∫–∏—Ç–∫–∞', '—Å–∫–∏–¥–∫–æ',\n",
    "            '–∫–∞—Ä–∑–∏–Ω–∞', '–∫–æ—Ä–∑–∏–Ω–æ'\n",
    "        ]\n",
    "        \n",
    "        correct_found = sum(1 for term in correct_terms if term in text_lower)\n",
    "        wrong_found = sum(1 for term in wrong_terms if term in text_lower)\n",
    "        \n",
    "        if correct_found + wrong_found > 0:\n",
    "            ecommerce_accuracy = correct_found / (correct_found + wrong_found)\n",
    "            if ecommerce_accuracy < 0.8:\n",
    "                metrics.improvement_suggestions.append(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ e-commerce —Ç–µ—Ä–º–∏–Ω—ã\")\n",
    "    \n",
    "    def _normalize_text(self, text: str) -> str:\n",
    "        \"\"\"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "        text = text.lower()\n",
    "        # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _create_empty_metrics(self, reason: str) -> QualityMetrics:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –º–µ—Ç—Ä–∏–∫\"\"\"\n",
    "        metrics = QualityMetrics()\n",
    "        metrics.overall_score = 0.0\n",
    "        metrics.quality_level = QualityLevel.VERY_POOR\n",
    "        metrics.improvement_suggestions = [reason]\n",
    "        return metrics\n",
    "\n",
    "print(\"‚úÖ SimpleQualityAssessor —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_ensemble_service"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/enhanced_transcriber/services/ensemble_service.py\n",
    "\"\"\"\n",
    "–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Ensemble Service –¥–ª—è Colab\n",
    "Simplified Ensemble Service for Colab\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import statistics\n",
    "from typing import List, Dict, Any\n",
    "from collections import Counter\n",
    "\n",
    "from ..core.interfaces.transcriber import ITranscriber\n",
    "from ..core.models.transcription_result import TranscriptionResult, TranscriptionStatus\n",
    "from .quality_assessor import SimpleQualityAssessor\n",
    "\n",
    "\n",
    "class SimpleEnsembleService:\n",
    "    \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Ensemble —Å–µ—Ä–≤–∏—Å –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        models: List[ITranscriber],\n",
    "        target_quality_threshold: float = 0.95\n",
    "    ):\n",
    "        if len(models) < 2:\n",
    "            raise ValueError(\"Ensemble requires at least 2 models\")\n",
    "        \n",
    "        self.models = models\n",
    "        self.target_quality_threshold = target_quality_threshold\n",
    "        self.quality_assessor = SimpleQualityAssessor()\n",
    "        \n",
    "        # –í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π (T-one –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)\n",
    "        self.model_weights = self._initialize_model_weights()\n",
    "        \n",
    "        print(f\"‚úÖ Ensemble service initialized with {len(models)} models\")\n",
    "        print(f\"üéØ Target quality: {target_quality_threshold:.1%}\")\n",
    "    \n",
    "    def _initialize_model_weights(self) -> Dict[str, float]:\n",
    "        \"\"\"–í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π\"\"\"\n",
    "        weights = {}\n",
    "        \n",
    "        for model in self.models:\n",
    "            if \"tone\" in model.model_name.lower():\n",
    "                weights[model.model_name] = 1.2  # T-one –ª—É—á—à–µ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ\n",
    "            elif \"whisper\" in model.model_name.lower():\n",
    "                weights[model.model_name] = 1.0\n",
    "            else:\n",
    "                weights[model.model_name] = 0.9\n",
    "        \n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        total_weight = sum(weights.values())\n",
    "        return {k: v/total_weight for k, v in weights.items()}\n",
    "    \n",
    "    async def transcribe_with_quality_target(\n",
    "        self,\n",
    "        audio_file: str,\n",
    "        language: str = \"ru\",\n",
    "        max_iterations: int = 3,\n",
    "        **kwargs\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ü–µ–ª–µ–≤—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º\"\"\"\n",
    "        \n",
    "        print(f\"üéµ Starting ensemble transcription: {audio_file}\")\n",
    "        print(f\"üéØ Target: {self.target_quality_threshold:.1%}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        best_result = None\n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\nüîÑ Iteration {iteration}/{max_iterations}\")\n",
    "            \n",
    "            try:\n",
    "                # Ensemble —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n",
    "                ensemble_result = await self._perform_ensemble_transcription(\n",
    "                    audio_file, language, iteration\n",
    "                )\n",
    "                \n",
    "                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "                quality_metrics = self.quality_assessor.assess_quality(\n",
    "                    ensemble_result.text,\n",
    "                    confidence=ensemble_result.confidence\n",
    "                )\n",
    "                ensemble_result.quality_metrics = quality_metrics\n",
    "                \n",
    "                quality_score = quality_metrics.overall_score\n",
    "                print(f\"üìä Quality achieved: {quality_score:.1%} ({quality_metrics.quality_level.value})\")\n",
    "                \n",
    "                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏\n",
    "                if quality_score >= self.target_quality_threshold:\n",
    "                    print(f\"üéØ TARGET ACHIEVED in iteration {iteration}!\")\n",
    "                    best_result = ensemble_result\n",
    "                    break\n",
    "                \n",
    "                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "                if not best_result or quality_score > best_result.quality_metrics.overall_score:\n",
    "                    best_result = ensemble_result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Iteration {iteration} failed: {e}\")\n",
    "                if iteration == max_iterations:\n",
    "                    raise\n",
    "        \n",
    "        if best_result:\n",
    "            best_result.processing_time = time.time() - start_time\n",
    "            \n",
    "            final_quality = best_result.quality_metrics.overall_score\n",
    "            target_achieved = \"üéØ\" if final_quality >= self.target_quality_threshold else \"‚ö†Ô∏è\"\n",
    "            print(f\"\\n{target_achieved} FINAL RESULT: {final_quality:.1%} quality\")\n",
    "            \n",
    "            return best_result\n",
    "        \n",
    "        raise RuntimeError(\"All ensemble iterations failed\")\n",
    "    \n",
    "    async def _perform_ensemble_transcription(\n",
    "        self,\n",
    "        audio_file: str,\n",
    "        language: str,\n",
    "        iteration: int\n",
    "    ) -> TranscriptionResult:\n",
    "        \"\"\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ ensemble —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\"\"\"\n",
    "        \n",
    "        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        print(f\"ü§ñ Running {len(self.models)} models in parallel...\")\n",
    "        \n",
    "        tasks = [\n",
    "            asyncio.create_task(\n",
    "                model.transcribe(audio_file, language),\n",
    "                name=f\"model_{model.model_name}\"\n",
    "            )\n",
    "            for model in self.models\n",
    "        ]\n",
    "        \n",
    "        # –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        successful_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, TranscriptionResult) and result.status == TranscriptionStatus.COMPLETED:\n",
    "                successful_results.append(result)\n",
    "                print(f\"   ‚úÖ {self.models[i].model_name}: {result.confidence:.1%} confidence\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå {self.models[i].model_name}: failed\")\n",
    "        \n",
    "        if not successful_results:\n",
    "            raise RuntimeError(\"All models failed\")\n",
    "        \n",
    "        print(f\"üìä Successful models: {len(successful_results)}/{len(self.models)}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞\n",
    "        consensus_result = self._create_consensus(successful_results)\n",
    "        \n",
    "        return consensus_result\n",
    "    \n",
    "    def _create_consensus(self, results: List[TranscriptionResult]) -> TranscriptionResult:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\"\"\"\n",
    "        \n",
    "        if len(results) == 1:\n",
    "            return results[0]\n",
    "        \n",
    "        print(\"üîÑ Creating weighted consensus...\")\n",
    "        \n",
    "        # Weighted voting –ø–æ —Å–ª–æ–≤–∞–º\n",
    "        consensus_text = self._weighted_word_consensus(results)\n",
    "        \n",
    "        # –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        avg_confidence = statistics.mean([r.confidence for r in results])\n",
    "        avg_processing_time = statistics.mean([r.processing_time for r in results])\n",
    "        \n",
    "        # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ confidence\n",
    "        best_result = max(results, key=lambda r: r.confidence)\n",
    "        \n",
    "        return TranscriptionResult(\n",
    "            text=consensus_text,\n",
    "            confidence=max(avg_confidence, best_result.confidence),\n",
    "            processing_time=avg_processing_time,\n",
    "            model_used=f\"Ensemble ({len(results)} models)\",\n",
    "            language_detected=best_result.language_detected,\n",
    "            status=TranscriptionStatus.COMPLETED,\n",
    "            provider_metadata={\n",
    "                \"ensemble_size\": len(results),\n",
    "                \"models_used\": [r.model_used for r in results],\n",
    "                \"consensus_method\": \"weighted_word_voting\",\n",
    "                \"avg_confidence\": avg_confidence,\n",
    "                \"best_individual_confidence\": best_result.confidence\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def _weighted_word_consensus(self, results: List[TranscriptionResult]) -> str:\n",
    "        \"\"\"Weighted –∫–æ–Ω—Å–µ–Ω—Å—É—Å –ø–æ —Å–ª–æ–≤–∞–º\"\"\"\n",
    "        \n",
    "        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        all_tokens = []\n",
    "        for result in results:\n",
    "            tokens = result.text.split()\n",
    "            weight = self.model_weights.get(result.model_used.split('(')[0].strip(), 1.0)\n",
    "            all_tokens.append({\n",
    "                'tokens': tokens,\n",
    "                'confidence': result.confidence,\n",
    "                'weight': weight\n",
    "            })\n",
    "        \n",
    "        if not all_tokens:\n",
    "            return \"\"\n",
    "        \n",
    "        # –ü–æ–∏—Å–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã\n",
    "        max_length = max(len(token_set['tokens']) for token_set in all_tokens)\n",
    "        \n",
    "        consensus_words = []\n",
    "        \n",
    "        for position in range(max_length):\n",
    "            position_candidates = {}\n",
    "            \n",
    "            # –°–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏\n",
    "            for token_set in all_tokens:\n",
    "                if position < len(token_set['tokens']):\n",
    "                    word = token_set['tokens'][position].lower()\n",
    "                    score = token_set['confidence'] * token_set['weight']\n",
    "                    \n",
    "                    if word in position_candidates:\n",
    "                        position_candidates[word] += score\n",
    "                    else:\n",
    "                        position_candidates[word] = score\n",
    "            \n",
    "            # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞\n",
    "            if position_candidates:\n",
    "                best_word = max(position_candidates.items(), key=lambda x: x[1])[0]\n",
    "                consensus_words.append(best_word)\n",
    "        \n",
    "        return ' '.join(consensus_words)\n",
    "    \n",
    "    def get_ensemble_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± ensemble\"\"\"\n",
    "        return {\n",
    "            \"models_count\": len(self.models),\n",
    "            \"models_info\": [model.get_model_info() for model in self.models],\n",
    "            \"model_weights\": self.model_weights,\n",
    "            \"target_quality_threshold\": self.target_quality_threshold,\n",
    "            \"consensus_method\": \"weighted_word_voting\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ SimpleEnsembleService —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "main_transcriber_section"
   },
   "source": [
    "## üöÄ 5. –ì–ª–∞–≤–Ω—ã–π Enhanced Transcriber –¥–ª—è Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_main_transcriber"
   },
   "outputs": [],
   "source": "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Enhanced Transcriber –∏–∑ —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\nimport sys\nimport os\nfrom pathlib import Path\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Enhanced Transcriber –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ GitHub\nenhanced_transcriber_path = \"/content/Giper/PopovAndrew/enhanced-transcriber\"\n\nif Path(enhanced_transcriber_path).exists():\n    print(\"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º Enhanced Transcriber –∏–∑ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\")\n    print(\"üîó https://github.com/Andrew821667/Giper/tree/main/PopovAndrew/enhanced-transcriber\")\n    \n    # –ò–º–ø–æ—Ä—Ç –≥–ª–∞–≤–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–∑ —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞\n    sys.path.insert(0, enhanced_transcriber_path)\n    from enhanced_transcriber import EnhancedTranscriber\n    \n    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–µ—Ä–∞ —Å —Ü–µ–ª–µ–≤—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º 95%+\n    transcriber = EnhancedTranscriber(target_quality=0.95, domain=\"ecommerce\")\n    \n    print(\"\\nüöÄ Initializing Enhanced Transcriber models...\")\n    print(\"üìä This may take a few minutes for model downloads...\")\n    print(\"üéØ Target: 95%+ quality for Russian e-commerce transcription\\n\")\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π\n    try:\n        await transcriber.initialize_models()\n        init_success = True\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"üìä INITIALIZATION RESULTS\")\n        print(\"=\"*60)\n        \n        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã\n        status = transcriber.get_system_status()\n        \n        print(f\"\\n‚úÖ SYSTEM STATUS:\")\n        print(f\"   üéØ Target Quality: {status['target_quality']:.1%}\")\n        print(f\"   üõí Domain: {status['domain']}\")\n        print(f\"   ü§ñ Models Ready: {len(transcriber.models)}\")\n        print(f\"   üîÑ Ensemble Ready: {status['system_ready']}\")\n        \n        if status['system_ready']:\n            print(\"\\nüéØ SYSTEM READY FOR 95%+ QUALITY TRANSCRIPTION!\")\n            print(\"‚úÖ All components loaded from GitHub repository\")\n        else:\n            print(\"\\n‚ö†Ô∏è System partially ready - some models may have failed\")\n            \n    except Exception as e:\n        print(f\"‚ùå Initialization failed: {e}\")\n        init_success = False\n    \nelse:\n    print(\"‚ùå Enhanced Transcriber –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏!\")\n    print(\"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é...\")\n    \n    # Fallback –∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏\n    from enhanced_transcriber.colab_transcriber import ColabEnhancedTranscriber\n    \n    transcriber = ColabEnhancedTranscriber(target_quality=0.95)\n    init_results = transcriber.initialize_models(use_whisper_model=\"base\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä INITIALIZATION RESULTS (FALLBACK)\")\n    print(\"=\"*60)\n    \n    print(\"\\n‚úÖ MODELS LOADED:\")\n    for model in init_results[\"models_loaded\"]:\n        print(f\"   ü§ñ {model}\")\n    \n    if init_results[\"models_failed\"]:\n        print(\"\\n‚ùå MODELS FAILED:\")\n        for model in init_results[\"models_failed\"]:\n            print(f\"   ‚ö†Ô∏è {model}\")\n    \n    print(f\"\\nüîÑ ENSEMBLE STATUS: {'‚úÖ Ready' if init_results['ensemble_ready'] else '‚ùå Not Available'}\")\n\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "testing_section"
   },
   "source": [
    "## üß™ 6. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_transcriber"
   },
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Enhanced Transcriber\n",
    "from enhanced_transcriber.colab_transcriber import ColabEnhancedTranscriber\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–µ—Ä–∞ —Å —Ü–µ–ª–µ–≤—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º 95%+\n",
    "transcriber = ColabEnhancedTranscriber(target_quality=0.95)\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "print(\"üöÄ Initializing Enhanced Transcriber models...\")\n",
    "print(\"üìä This may take a few minutes for model downloads...\\n\")\n",
    "\n",
    "init_results = transcriber.initialize_models(use_whisper_model=\"base\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä INITIALIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ MODELS LOADED:\")\n",
    "for model in init_results[\"models_loaded\"]:\n",
    "    print(f\"   ü§ñ {model}\")\n",
    "\n",
    "if init_results[\"models_failed\"]:\n",
    "    print(\"\\n‚ùå MODELS FAILED:\")\n",
    "    for model in init_results[\"models_failed\"]:\n",
    "        print(f\"   ‚ö†Ô∏è {model}\")\n",
    "\n",
    "print(f\"\\nüîÑ ENSEMBLE STATUS: {'‚úÖ Ready' if init_results['ensemble_ready'] else '‚ùå Not Available'}\")\n",
    "\n",
    "if init_results[\"ensemble_ready\"]:\n",
    "    print(\"\\nüéØ SYSTEM READY FOR 95%+ QUALITY TRANSCRIPTION!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Running in single-model mode\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_audio_section"
   },
   "source": [
    "## üìÅ 7. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_files"
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤\n",
    "from google.colab import files\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\")\n",
    "print(\"üéµ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: WAV, MP3, M4A, FLAC, OGG\")\n",
    "print(\"üá∑üá∫ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ –∞—É–¥–∏–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\\n\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "uploaded = files.upload()\n",
    "\n",
    "# –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ –ø–∞–ø–∫—É /content\n",
    "audio_files = []\n",
    "for filename in uploaded.keys():\n",
    "    file_path = Path('/content') / filename\n",
    "    shutil.move(filename, file_path)\n",
    "    audio_files.append(str(file_path))\n",
    "    print(f\"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}\")\n",
    "\n",
    "print(f\"\\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(audio_files)}\")\n",
    "print(\"üéØ –ì–æ—Ç–æ–≤ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ 95%+!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "transcription_testing_section"
   },
   "source": [
    "## üéØ 8. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_single_file"
   },
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "if audio_files:\n",
    "    test_file = audio_files[0]  # –ü–µ—Ä–≤—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
    "    print(f\"üéµ Testing file: {Path(test_file).name}\")\n",
    "    print(f\"üìÅ Path: {test_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ ENHANCED TRANSCRIBER - QUALITY TEST (TARGET: 95%+)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # –ó–∞–ø—É—Å–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å ensemble (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)\n",
    "    result = await transcriber.transcribe(\n",
    "        audio_file=test_file,\n",
    "        language=\"ru\",\n",
    "        use_ensemble=True  # –í–∫–ª—é—á–∞–µ–º ensemble –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "    )\n",
    "    \n",
    "    # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "    transcriber.print_result(result)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤\")\n",
    "    print(\"üìÅ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â—É—é —è—á–µ–π–∫—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_batch_files"
   },
   "outputs": [],
   "source": [
    "# –ü–∞–∫–µ—Ç–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "if len(audio_files) > 1:\n",
    "    print(f\"üì¶ BATCH TESTING - {len(audio_files)} files\")\n",
    "    print(\"üéØ Target Quality: 95%+ for each file\")\n",
    "    print(\"üîÑ Using Ensemble mode for maximum quality\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, audio_file in enumerate(audio_files, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÅ FILE {i}/{len(audio_files)}: {Path(audio_file).name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å ensemble\n",
    "            result = await transcriber.transcribe(\n",
    "                audio_file=audio_file,\n",
    "                language=\"ru\",\n",
    "                use_ensemble=True\n",
    "            )\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "            quality = result.quality_metrics.overall_score if result.quality_metrics else 0.0\n",
    "            target_achieved = \"üéØ\" if quality >= 0.95 else \"‚ö†Ô∏è\"\n",
    "            \n",
    "            print(f\"\\n{target_achieved} RESULT:\")\n",
    "            print(f\"   Quality: {quality:.1%}\")\n",
    "            print(f\"   Confidence: {result.confidence:.1%}\")\n",
    "            print(f\"   Words: {len(result.text.split())}\")\n",
    "            print(f\"   Time: {result.processing_time:.1f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed: {e}\")\n",
    "    \n",
    "    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    if results:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üìä BATCH RESULTS SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        successful = len(results)\n",
    "        qualities = [r.quality_metrics.overall_score for r in results if r.quality_metrics]\n",
    "        target_achieved = sum(1 for q in qualities if q >= 0.95)\n",
    "        \n",
    "        print(f\"‚úÖ Successful: {successful}/{len(audio_files)}\")\n",
    "        if qualities:\n",
    "            avg_quality = sum(qualities) / len(qualities)\n",
    "            print(f\"üìä Average Quality: {avg_quality:.1%}\")\n",
    "            print(f\"üéØ Target Achieved: {target_achieved}/{len(qualities)} files\")\n",
    "            print(f\"üìà Success Rate: {target_achieved/len(qualities):.1%}\")\n",
    "\n",
    "elif len(audio_files) == 1:\n",
    "    print(\"‚ÑπÔ∏è Only one file uploaded. Use the previous cell for detailed testing.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No audio files uploaded\")\n",
    "    print(\"üìÅ Please upload audio files first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quality_comparison_section"
   },
   "source": [
    "## üìä 9. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compare_models"
   },
   "outputs": [],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if audio_files:\n",
    "    test_file = audio_files[0]\n",
    "    print(f\"üî¨ QUALITY COMPARISON TEST\")\n",
    "    print(f\"üìÅ File: {Path(test_file).name}\")\n",
    "    print(f\"üéØ Comparing: Single models vs Ensemble\\n\")\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    # –¢–µ—Å—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "    for model in transcriber.models:\n",
    "        print(f\"ü§ñ Testing {model.model_name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = await model.transcribe(test_file, \"ru\")\n",
    "            \n",
    "            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "            from enhanced_transcriber.services.quality_assessor import SimpleQualityAssessor\n",
    "            assessor = SimpleQualityAssessor()\n",
    "            quality_metrics = assessor.assess_quality(\n",
    "                result.text, \n",
    "                confidence=result.confidence\n",
    "            )\n",
    "            \n",
    "            comparison_results.append({\n",
    "                \"model\": model.model_name,\n",
    "                \"quality\": quality_metrics.overall_score,\n",
    "                \"confidence\": result.confidence,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"words\": len(result.text.split()),\n",
    "                \"text_preview\": result.text[:100] + \"...\" if len(result.text) > 100 else result.text\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ Quality: {quality_metrics.overall_score:.1%}, Time: {time.time() - start_time:.1f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç Ensemble\n",
    "    if transcriber.ensemble_service:\n",
    "        print(f\"\\nüîÑ Testing Ensemble (Target: 95%+)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            ensemble_result = await transcriber.transcribe(\n",
    "                audio_file=test_file,\n",
    "                language=\"ru\",\n",
    "                use_ensemble=True\n",
    "            )\n",
    "            \n",
    "            comparison_results.append({\n",
    "                \"model\": \"Ensemble (95%+ Target)\",\n",
    "                \"quality\": ensemble_result.quality_metrics.overall_score,\n",
    "                \"confidence\": ensemble_result.confidence,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"words\": len(ensemble_result.text.split()),\n",
    "                \"text_preview\": ensemble_result.text[:100] + \"...\" if len(ensemble_result.text) > 100 else ensemble_result.text\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ Quality: {ensemble_result.quality_metrics.overall_score:.1%}, Time: {time.time() - start_time:.1f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "    \n",
    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "    if comparison_results:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üìä QUALITY COMPARISON RESULTS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É\n",
    "        comparison_results.sort(key=lambda x: x['quality'], reverse=True)\n",
    "        \n",
    "        print(f\"{'Model':<25} {'Quality':<10} {'Confidence':<12} {'Time':<8} {'Words':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for result in comparison_results:\n",
    "            quality_emoji = \"üéØ\" if result['quality'] >= 0.95 else \"‚úÖ\" if result['quality'] >= 0.8 else \"‚ö†Ô∏è\"\n",
    "            print(f\"{result['model']:<25} {quality_emoji}{result['quality']:.1%} {result['confidence']:.1%} {result['time']:.1f}s {result['words']}\")\n",
    "        \n",
    "        # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        best = comparison_results[0]\n",
    "        print(f\"\\nüèÜ BEST RESULT: {best['model']}\")\n",
    "        print(f\"   Quality: {best['quality']:.1%}\")\n",
    "        print(f\"   Target Achieved: {'‚úÖ YES' if best['quality'] >= 0.95 else '‚ö†Ô∏è NO'}\")\n",
    "        print(f\"   Text Preview: {best['text_preview']}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No audio files uploaded for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_stats_section"
   },
   "source": [
    "## üìà 10. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_final_stats"
   },
   "outputs": [],
   "source": [
    "# –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã Enhanced Transcriber\n",
    "stats = transcriber.get_stats()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ ENHANCED TRANSCRIBER - FINAL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if stats.get(\"message\"):\n",
    "    print(f\"‚ÑπÔ∏è {stats['message']}\")\n",
    "else:\n",
    "    print(f\"üìä PERFORMANCE METRICS:\")\n",
    "    print(f\"   Total Transcriptions: {stats['total_transcriptions']}\")\n",
    "    print(f\"   Successful: {stats['successful_transcriptions']}\")\n",
    "    print(f\"   Success Rate: {stats['success_rate']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ QUALITY METRICS:\")\n",
    "    print(f\"   Average Quality: {stats['average_quality']:.1%}\")\n",
    "    print(f\"   95%+ Achievements: {stats['target_achievements']}\")\n",
    "    print(f\"   Target Success Rate: {stats['target_achievement_rate']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nü§ñ SYSTEM CONFIGURATION:\")\n",
    "    print(f\"   Models Available: {stats['models_count']}\")\n",
    "    print(f\"   Ensemble Mode: {'‚úÖ Active' if stats['ensemble_available'] else '‚ùå Disabled'}\")\n",
    "    print(f\"   Target Quality: 95%+\")\n",
    "    print(f\"   Domain: E-commerce (Russian)\")\n",
    "    \n",
    "    # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    if stats['target_achievement_rate'] >= 0.9:\n",
    "        performance = \"üéØ EXCELLENT (90%+ target achievement)\"\n",
    "    elif stats['target_achievement_rate'] >= 0.7:\n",
    "        performance = \"‚úÖ GOOD (70%+ target achievement)\"\n",
    "    elif stats['target_achievement_rate'] >= 0.5:\n",
    "        performance = \"‚ö†Ô∏è FAIR (50%+ target achievement)\"\n",
    "    else:\n",
    "        performance = \"‚ùå NEEDS IMPROVEMENT (<50% target achievement)\"\n",
    "    \n",
    "    print(f\"\\nüìà OVERALL PERFORMANCE: {performance}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ ENHANCED TRANSCRIBER TESTING COMPLETED\")\n",
    "print(\"‚úÖ Ready for integration into larger projects!\")\n",
    "print(\"üõí Specialized for e-commerce domain (–ì–∏–ø–µ—Ä –û–Ω–ª–∞–π–Ω)\")\n",
    "print(\"üá∑üá∫ Optimized for Russian language transcription\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion_section"
   },
   "source": [
    "## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "### ‚úÖ –ß—Ç–æ –±—ã–ª–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ:\n",
    "\n",
    "- **T-one ASR** - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "- **Whisper Local** - –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å OpenAI –±–µ–∑ API\n",
    "- **Ensemble Mode** - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ **95%+**\n",
    "- **E-commerce Post-processing** - –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –æ–Ω–ª–∞–π–Ω-—Ç–æ—Ä–≥–æ–≤–ª–∏\n",
    "- **Quality Assessment** - –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\n",
    "\n",
    "### üéØ –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
    "\n",
    "1. **–ö–∞—á–µ—Å—Ç–≤–æ 95%+** - –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ ensemble –ø–æ–¥—Ö–æ–¥\n",
    "2. **–†—É—Å—Å–∫–∏–π —è–∑—ã–∫** - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å T-one –º–æ–¥–µ–ª—å—é\n",
    "3. **E-commerce –¥–æ–º–µ–Ω** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
    "4. **–õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** - –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–Ω–µ—à–Ω–∏—Ö API\n",
    "5. **Production Ready** - –≥–æ—Ç–æ–≤ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –º–∞—Å—à—Ç–∞–±–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã\n",
    "\n",
    "### üöÄ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:\n",
    "\n",
    "Enhanced Transcriber –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ **–º–∞—Å—à—Ç–∞–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç \"–ì–∏–ø–µ—Ä –û–Ω–ª–∞–π–Ω\"** –∫–∞–∫ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∑–≤–æ–Ω–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º **95%+**.\n",
    "\n",
    "---\n",
    "*–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ: Popov Andrew*  \n",
    "*–¶–µ–ª—å: –ö–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ 95%+ –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞* ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}