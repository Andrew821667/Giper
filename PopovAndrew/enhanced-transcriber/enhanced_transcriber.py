"""
Enhanced Transcriber - –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ 95%+
Complete integration for 95%+ transcription quality
"""

import asyncio
import logging
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

# Core components
from providers.tone import ToneTranscriber
from providers.whisper.working_whisper import WorkingWhisperTranscriber
from providers.whisper import WhisperOpenAITranscriber
from services.ensemble_service import EnsembleTranscriptionService
from services.audio_processor import AudioProcessorService
from services.quality_assessor import QualityAssessmentService
from core.models.transcription_result import TranscriptionResult
from core.models.config_models import TranscriptionConfig, ECommerceConfig

logger = logging.getLogger(__name__)


class EnhancedTranscriber:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å Enhanced Transcriber –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ 95%+
    Main Enhanced Transcriber class for achieving 95%+ quality
    """
    
    def __init__(
        self,
        openai_api_key: Optional[str] = None,
        target_quality: float = 0.95,
        enable_audio_enhancement: bool = True,
        enable_quality_assessment: bool = True,
        domain: str = "ecommerce"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Enhanced Transcriber
        
        Args:
            openai_api_key: OpenAI API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            target_quality: –¶–µ–ª–µ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (0.95 = 95%)
            enable_audio_enhancement: –í–∫–ª—é—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –∞—É–¥–∏–æ
            enable_quality_assessment: –í–∫–ª—é—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
            domain: –î–æ–º–µ–Ω –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        self.target_quality = target_quality
        self.domain = domain
        self.openai_api_key = openai_api_key
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = TranscriptionConfig()
        self.ecommerce_config = ECommerceConfig() if domain == "ecommerce" else None
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.models = []
        self.audio_processor = None
        self.quality_assessor = None
        self.ensemble_service = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "total_transcriptions": 0,
            "successful_transcriptions": 0,
            "average_quality": 0.0,
            "quality_95_plus_count": 0
        }
        
        logger.info(f"üéØ Enhanced Transcriber initialized (target: {target_quality:.1%})")
    
    async def initialize(self) -> Dict[str, Any]:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
        
        Returns:
            Dict: –°—Ç–∞—Ç—É—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        logger.info("üöÄ Starting Enhanced Transcriber initialization...")
        
        init_results = {
            "models": [],
            "audio_processor": False,
            "quality_assessor": False,
            "ensemble_service": False,
            "ready": False
        }
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        await self._initialize_models(init_results)
        
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        if len(self.models) > 0:
            await self._initialize_audio_processor(init_results)
        
        # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        await self._initialize_quality_assessor(init_results)
        
        # 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ensemble —Å–µ—Ä–≤–∏—Å–∞
        if len(self.models) >= 2:
            await self._initialize_ensemble_service(init_results)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
        init_results["ready"] = (
            len(self.models) > 0 and
            (self.ensemble_service is not None or len(self.models) == 1)
        )
        
        if init_results["ready"]:
            logger.info("‚úÖ Enhanced Transcriber ready for 95%+ quality transcription!")
        else:
            logger.error("‚ùå Enhanced Transcriber initialization failed")
        
        return init_results
    
    async def _initialize_models(self, init_results: Dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("ü§ñ Initializing transcription models...")
        
        # 1. T-one (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)
        try:
            tone_model = ToneTranscriber("voicekit/tone-ru")
            self.models.append(tone_model)
            init_results["models"].append({
                "name": "T-one Russian",
                "status": "success",
                "priority": "high"
            })
            logger.info("‚úÖ T-one model loaded (Russian specialist)")
        except Exception as e:
            init_results["models"].append({
                "name": "T-one Russian", 
                "status": "failed",
                "error": str(e)
            })
            logger.warning(f"‚ö†Ô∏è T-one model failed: {e}")
        
        # 2. Whisper Local
        try:
            whisper_local = WorkingWhisperTranscriber("large-v3", device="auto")
            self.models.append(whisper_local)
            init_results["models"].append({
                "name": "Whisper Local",
                "status": "success",
                "priority": "large-v3"
            })
            logger.info("‚úÖ Whisper Local model loaded")
        except Exception as e:
            init_results["models"].append({
                "name": "Whisper Local",
                "status": "failed", 
                "error": str(e)
            })
            logger.warning(f"‚ö†Ô∏è Whisper Local model failed: {e}")
        
        # 3. OpenAI Whisper (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á)
        if self.openai_api_key:
            try:
                whisper_openai = WhisperOpenAITranscriber(self.openai_api_key)
                self.models.append(whisper_openai)
                init_results["models"].append({
                    "name": "OpenAI Whisper",
                    "status": "success",
                    "priority": "high"
                })
                logger.info("‚úÖ OpenAI Whisper API available")
            except Exception as e:
                init_results["models"].append({
                    "name": "OpenAI Whisper",
                    "status": "failed",
                    "error": str(e)
                })
                logger.warning(f"‚ö†Ô∏è OpenAI Whisper failed: {e}")
        
        logger.info(f"üìä Models loaded: {len(self.models)} / {len(init_results['models'])}")
    
    async def _initialize_audio_processor(self, init_results: Dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
        try:
            self.audio_processor = AudioProcessorService(
                enable_noise_reduction=True,
                enable_volume_normalization=True,
                enable_speech_enhancement=True,
                target_sample_rate=16000,
                convert_to_mono=True
            )
            init_results["audio_processor"] = True
            logger.info("‚úÖ Audio processor initialized")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Audio processor initialization failed: {e}")
    
    async def _initialize_quality_assessor(self, init_results: Dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        try:
            self.quality_assessor = QualityAssessmentService(
                enable_semantic_analysis=True,
                enable_domain_analysis=True,
                ecommerce_config=self.ecommerce_config
            )
            init_results["quality_assessor"] = True
            logger.info("‚úÖ Quality assessor initialized")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Quality assessor initialization failed: {e}")
    
    async def _initialize_ensemble_service(self, init_results: Dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ensemble —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            self.ensemble_service = EnsembleTranscriptionService(
                models=self.models,
                audio_processor=self.audio_processor,
                quality_assessor=self.quality_assessor,
                target_quality_threshold=self.target_quality
            )
            init_results["ensemble_service"] = True
            logger.info(f"‚úÖ Ensemble service initialized with {len(self.models)} models")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ensemble service initialization failed: {e}")
    
    async def transcribe(
        self,
        audio_file: str,
        language: str = "ru",
        max_quality_iterations: int = 3,
        force_target_quality: bool = True,
        **kwargs
    ) -> TranscriptionResult:
        """
        –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ü–µ–ª–µ–≤—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º 95%+
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language: –Ø–∑—ã–∫
            max_quality_iterations: –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            force_target_quality: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Å—Ç–∏–≥–∞—Ç—å —Ü–µ–ª–µ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            TranscriptionResult: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        if not Path(audio_file).exists():
            raise FileNotFoundError(f"Audio file not found: {audio_file}")
        
        if not self.models:
            raise RuntimeError("No transcription models available")
        
        start_time = time.time()
        logger.info(f"üéµ Starting transcription: {Path(audio_file).name}")
        logger.info(f"üéØ Target quality: {self.target_quality:.1%}")
        
        try:
            # Ensemble —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            if self.ensemble_service:
                result = await self.ensemble_service.transcribe_with_quality_target(
                    audio_file=audio_file,
                    language=language,
                    domain=self.domain,
                    max_iterations=max_quality_iterations,
                    **kwargs
                )
            
            # Fallback: –æ–¥–∏–Ω–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å
            else:
                logger.info("üîß Using single model fallback")
                result = await self.models[0].transcribe(audio_file, language, **kwargs)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
                if self.quality_assessor:
                    quality_metrics = await self.quality_assessor.assess_quality(
                        result.text,
                        audio_file,
                        domain=self.domain
                    )
                    result.quality_metrics = quality_metrics
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._update_stats(result)
            
            total_time = time.time() - start_time
            result.processing_time = total_time
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            self._log_result(result, audio_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            if force_target_quality and result.quality_metrics:
                if result.quality_metrics.overall_score < self.target_quality:
                    logger.warning(
                        f"‚ö†Ô∏è Target quality not achieved: "
                        f"{result.quality_metrics.overall_score:.1%} < {self.target_quality:.1%}"
                    )
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Transcription failed: {e}")
            self.stats["total_transcriptions"] += 1
            raise
    
    async def transcribe_batch(
        self,
        audio_files: List[str],
        language: str = "ru",
        max_concurrent: int = 3,
        **kwargs
    ) -> List[TranscriptionResult]:
        """
        –ü–∞–∫–µ—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
        
        Args:
            audio_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º
            language: –Ø–∑—ã–∫
            max_concurrent: –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            List[TranscriptionResult]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
        """
        logger.info(f"üì¶ Starting batch transcription: {len(audio_files)} files")
        
        # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def transcribe_with_semaphore(audio_file: str) -> TranscriptionResult:
            async with semaphore:
                return await self.transcribe(audio_file, language, **kwargs)
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
        tasks = [transcribe_with_semaphore(audio_file) for audio_file in audio_files]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        successful_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå File {audio_files[i]} failed: {result}")
                # –°–æ–∑–¥–∞–µ–º failed —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                failed_result = TranscriptionResult(
                    text="",
                    confidence=0.0,
                    processing_time=0.0,
                    model_used="ensemble",
                    language_detected=language,
                    status="failed",
                    error_message=str(result)
                )
                successful_results.append(failed_result)
            else:
                successful_results.append(result)
        
        success_count = sum(1 for r in successful_results if r.text)
        logger.info(f"‚úÖ Batch completed: {success_count}/{len(audio_files)} successful")
        
        return successful_results
    
    def _update_stats(self, result: TranscriptionResult):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.stats["total_transcriptions"] += 1
        
        if result.text and result.status != "failed":
            self.stats["successful_transcriptions"] += 1
            
            if result.quality_metrics:
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                current_avg = self.stats["average_quality"]
                current_count = self.stats["successful_transcriptions"]
                new_quality = result.quality_metrics.overall_score
                
                self.stats["average_quality"] = (
                    (current_avg * (current_count - 1) + new_quality) / current_count
                )
                
                # –ü–æ–¥—Å—á–µ—Ç –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π —Ü–µ–ª–µ–≤–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                if new_quality >= self.target_quality:
                    self.stats["quality_95_plus_count"] += 1
    
    def _log_result(self, result: TranscriptionResult, audio_file: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        filename = Path(audio_file).name
        
        if result.quality_metrics:
            quality_info = f"{result.quality_metrics.overall_score:.1%} ({result.quality_metrics.quality_level.value})"
            target_achieved = "üéØ" if result.quality_metrics.overall_score >= self.target_quality else "‚ö†Ô∏è"
        else:
            quality_info = "N/A"
            target_achieved = "‚ùì"
        
        logger.info(
            f"{target_achieved} {filename}: "
            f"Quality={quality_info}, "
            f"Confidence={result.confidence:.1%}, "
            f"Time={result.processing_time:.1f}s, "
            f"Words={len(result.text.split())}"
        )
    
    def get_system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        return {
            "system_ready": bool(self.models),
            "models_count": len(self.models),
            "ensemble_available": self.ensemble_service is not None,
            "audio_processor_available": self.audio_processor is not None,
            "quality_assessor_available": self.quality_assessor is not None,
            "target_quality": self.target_quality,
            "domain": self.domain,
            "statistics": self.stats.copy()
        }
    
    def get_quality_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
        if self.stats["total_transcriptions"] == 0:
            return {"message": "No transcriptions performed yet"}
        
        success_rate = self.stats["successful_transcriptions"] / self.stats["total_transcriptions"]
        target_achievement_rate = (
            self.stats["quality_95_plus_count"] / self.stats["successful_transcriptions"]
            if self.stats["successful_transcriptions"] > 0 else 0
        )
        
        return {
            "total_transcriptions": self.stats["total_transcriptions"],
            "successful_transcriptions": self.stats["successful_transcriptions"],
            "success_rate": success_rate,
            "average_quality": self.stats["average_quality"],
            "target_quality": self.target_quality,
            "target_achievement_count": self.stats["quality_95_plus_count"],
            "target_achievement_rate": target_achievement_rate,
            "quality_level": (
                "üéØ Excellent" if target_achievement_rate > 0.9 else
                "‚úÖ Good" if target_achievement_rate > 0.7 else
                "‚ö†Ô∏è Needs improvement"
            )
        }
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        logger.info("üßπ Cleaning up Enhanced Transcriber resources...")
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∞—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        if self.audio_processor and hasattr(self.audio_processor, 'temp_dir'):
            temp_dir = Path(self.audio_processor.temp_dir)
            if temp_dir.exists():
                for temp_file in temp_dir.glob("*_enhanced_*"):
                    try:
                        temp_file.unlink()
                    except Exception as e:
                        logger.warning(f"Failed to remove temp file {temp_file}: {e}")
        
        logger.info("‚úÖ Cleanup completed")