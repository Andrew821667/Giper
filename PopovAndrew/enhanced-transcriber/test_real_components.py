#!/usr/bin/env python3
"""
Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ² Enhanced Transcriber
Test real Enhanced Transcriber components
"""

import sys
import asyncio
import time
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Ğ¿ÑƒÑ‚ÑŒ
sys.path.insert(0, str(Path(__file__).parent))

async def test_quality_assessor():
    """Ğ¢ĞµÑÑ‚ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
    print("ğŸ“Š Testing Quality Assessor...")
    
    from services.quality_assessor import QualityAssessmentService
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ°
        assessor = QualityAssessmentService(
            enable_semantic_analysis=False,  # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ñ‹
            enable_domain_analysis=True
        )
        
        # Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
        test_text = "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ, Ñ…Ğ¾Ñ‡Ñƒ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‚ÑŒ Ğ·Ğ°ĞºĞ°Ğ· Ğ½Ğ° Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºÑƒ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚-Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½"
        
        # ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        quality_metrics = await assessor.assess_quality(
            transcribed_text=test_text,
            audio_file="/tmp/test.wav",  # ĞœĞ¾Ğº Ñ„Ğ°Ğ¹Ğ»
            domain="ecommerce"
        )
        
        print(f"âœ… Quality assessment completed")
        print(f"   Overall Score: {quality_metrics.overall_score:.1%}")
        print(f"   Quality Level: {quality_metrics.quality_level.value}")
        print(f"   Word Count: {quality_metrics.word_count}")
        print(f"   Vocabulary Richness: {quality_metrics.vocabulary_richness:.2f}")
        
        if quality_metrics.improvement_suggestions:
            print(f"   Suggestions: {', '.join(quality_metrics.improvement_suggestions)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Quality Assessor test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_audio_processor():
    """Ğ¢ĞµÑÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°"""
    print("\nğŸµ Testing Audio Processor...")
    
    from services.audio_processor import AudioProcessorService
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°
        processor = AudioProcessorService(
            enable_noise_reduction=True,
            enable_volume_normalization=True,
            enable_speech_enhancement=True
        )
        
        print(f"âœ… Audio Processor created")
        print(f"   Noise reduction: enabled")
        print(f"   Volume normalization: enabled") 
        print(f"   Speech enhancement: enabled")
        print(f"   Target sample rate: {processor.target_sample_rate}Hz")
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
        test_audio = "/tmp/test_audio_proc.wav"
        Path(test_audio).touch()
        
        try:
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°ÑƒĞ´Ğ¸Ğ¾ (Ğ±ĞµĞ· librosa Ğ±ÑƒĞ´ĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹)
            metadata = await processor.analyze_audio(test_audio)
            
            print(f"   Audio analysis completed")
            print(f"   File size: {metadata.file_size} bytes")
            print(f"   Format: {metadata.format.value}")
            print(f"   Quality score: {metadata.quality_score:.2f}")
            
        finally:
            if Path(test_audio).exists():
                Path(test_audio).unlink()
        
        return True
        
    except Exception as e:
        print(f"âŒ Audio Processor test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_ensemble_service_creation():
    """Ğ¢ĞµÑÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ensemble ÑĞµÑ€Ğ²Ğ¸ÑĞ°"""
    print("\nğŸ”„ Testing Ensemble Service Creation...")
    
    from services.ensemble_service import EnsembleTranscriptionService
    from core.models.transcription_result import TranscriptionResult, TranscriptionStatus
    
    # ĞœĞ¾Ğº Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ°Ğ¹Ğ±ĞµÑ€
    class TestTranscriber:
        def __init__(self, name):
            self.model_name_str = name
        
        @property
        def model_name(self):
            return self.model_name_str
        
        def get_model_info(self):
            return {"name": self.model_name_str, "provider": "test"}
        
        async def transcribe(self, audio_file, language="ru"):
            await asyncio.sleep(0.05)  # Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
            return TranscriptionResult(
                text=f"Test result from {self.model_name_str}",
                confidence=0.85,
                processing_time=0.05,
                model_used=self.model_name_str,
                language_detected=language,
                status=TranscriptionStatus.COMPLETED
            )
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        models = [
            TestTranscriber("T-one Test"),
            TestTranscriber("Whisper Test")
        ]
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ensemble ÑĞµÑ€Ğ²Ğ¸ÑĞ°
        ensemble = EnsembleTranscriptionService(
            models=models,
            target_quality_threshold=0.95
        )
        
        print(f"âœ… Ensemble Service created")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
        info = ensemble.get_ensemble_info()
        print(f"   Models count: {info['models_count']}")
        print(f"   Target quality: {info['target_quality_threshold']:.1%}")
        print(f"   Consensus method: {info['consensus_method']}")
        
        # Ğ’ĞµÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        print(f"   Model weights: {info['model_weights']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ensemble Service test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_config_models():
    """Ğ¢ĞµÑÑ‚ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"""
    print("\nâš™ï¸ Testing Configuration Models...")
    
    try:
        from core.models.config_models import TranscriptionConfig, ECommerceConfig, ModelProvider
        
        # Ğ¢ĞµÑÑ‚ ECommerceConfig
        ecommerce_config = ECommerceConfig()
        terms = ecommerce_config.get_default_ecommerce_terms()
        
        print(f"âœ… ECommerceConfig created")
        print(f"   E-commerce terms loaded: {len(terms)} terms")
        print(f"   Example corrections: {dict(list(terms.items())[:3])}")
        
        # Ğ¢ĞµÑÑ‚ TranscriptionConfig
        config = TranscriptionConfig()
        models = config.get_default_models()
        
        print(f"âœ… TranscriptionConfig created")
        print(f"   Default models: {len(models)}")
        print(f"   Available models: {list(models.keys())}")
        print(f"   Default strategy: {config.default_strategy.value}")
        print(f"   Target quality: {config.quality_threshold:.1%}")
        
        # Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        optimal = config.get_optimal_model("ru", "good", "ecommerce")
        print(f"   Optimal for Russian/good/ecommerce: {optimal}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Config Models test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_data_models():
    """Ğ¢ĞµÑÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    print("\nğŸ“Š Testing Data Models...")
    
    try:
        from core.models.transcription_result import TranscriptionResult, TranscriptionStatus, WordTimestamp
        from core.models.quality_metrics import QualityMetrics, QualityLevel
        from core.models.audio_metadata import AudioMetadata, AudioFormat, AudioQuality
        
        # Ğ¢ĞµÑÑ‚ TranscriptionResult
        result = TranscriptionResult(
            text="Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸",
            confidence=0.92,
            processing_time=2.5,
            model_used="Test Model",
            language_detected="ru",
            status=TranscriptionStatus.COMPLETED
        )
        
        print(f"âœ… TranscriptionResult created")
        print(f"   Text: {result.text}")
        print(f"   Confidence: {result.confidence:.1%}")
        print(f"   Status: {result.status.value}")
        
        # Ğ¢ĞµÑÑ‚ QualityMetrics
        metrics = QualityMetrics()
        metrics.word_count = 4
        metrics.unique_words_count = 4
        metrics.vocabulary_richness = 1.0
        metrics.update_overall_assessment()
        
        print(f"âœ… QualityMetrics created")
        print(f"   Overall score: {metrics.overall_score:.1%}")
        print(f"   Quality level: {metrics.quality_level.value}")
        
        # Ğ¢ĞµÑÑ‚ AudioMetadata
        metadata = AudioMetadata(
            file_path="/tmp/test.wav",
            file_size=1024000,
            duration=60.0,
            sample_rate=16000,
            channels=1,
            format=AudioFormat.WAV
        )
        
        print(f"âœ… AudioMetadata created")
        print(f"   Duration: {metadata.duration_formatted}")
        print(f"   Size: {metadata.file_size_mb:.1f} MB")
        print(f"   Suitable for transcription: {metadata.is_suitable_for_transcription()}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Data Models test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²"""
    print("=" * 80)
    print("ğŸ§ª ENHANCED TRANSCRIBER - REAL COMPONENTS TEST")
    print("=" * 80)
    
    start_time = time.time()
    
    tests = [
        ("Data Models", test_data_models),
        ("Configuration Models", test_config_models),
        ("Quality Assessor", test_quality_assessor),
        ("Audio Processor", test_audio_processor),
        ("Ensemble Service", test_ensemble_service_creation),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            success = await test_func()
            if success:
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âŒ {test_name} test crashed: {e}")
            failed += 1
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 80)
    print("ğŸ“Š TEST RESULTS SUMMARY")
    print("=" * 80)
    print(f"âœ… Tests passed: {passed}")
    print(f"âŒ Tests failed: {failed}")
    print(f"ğŸ“Š Success rate: {passed/(passed+failed):.1%}" if (passed+failed) > 0 else "No tests run")
    print(f"â±ï¸ Total time: {total_time:.2f}s")
    
    if failed == 0:
        print("\nğŸ‰ ALL REAL COMPONENTS WORKING PERFECTLY!")
        print("âœ… Enhanced Transcriber architecture is solid")
        print("ğŸ¯ Ready for 95%+ quality transcription")
    else:
        print(f"\nâš ï¸ {failed} components need attention")
        print("ğŸ”§ Fix the failing components before production use")
    
    print("=" * 80)

if __name__ == "__main__":
    asyncio.run(main())