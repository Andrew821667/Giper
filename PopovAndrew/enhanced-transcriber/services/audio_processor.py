"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
Audio processor service for quality enhancement before transcription
"""

import asyncio
import time
import logging
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import tempfile
import shutil

from core.interfaces.audio_processor import IAudioProcessor
from core.models.audio_metadata import AudioMetadata, AudioFormat, AudioQuality

logger = logging.getLogger(__name__)


class AudioProcessorService(IAudioProcessor):
    """
    –°–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    Audio processing service for maximum transcription quality
    """
    
    def __init__(
        self,
        enable_noise_reduction: bool = True,
        enable_volume_normalization: bool = True,
        enable_speech_enhancement: bool = True,
        target_sample_rate: int = 16000,
        convert_to_mono: bool = True,
        temp_dir: Optional[str] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        Args:
            enable_noise_reduction: –í–∫–ª—é—á–∏—Ç—å —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
            enable_volume_normalization: –í–∫–ª—é—á–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            enable_speech_enhancement: –í–∫–ª—é—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ—á–∏
            target_sample_rate: –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            convert_to_mono: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –º–æ–Ω–æ
            temp_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        self.enable_noise_reduction = enable_noise_reduction
        self.enable_volume_normalization = enable_volume_normalization
        self.enable_speech_enhancement = enable_speech_enhancement
        self.target_sample_rate = target_sample_rate
        self.convert_to_mono = convert_to_mono
        self.temp_dir = Path(temp_dir) if temp_dir else Path(tempfile.gettempdir())
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
        self._check_dependencies()
    
    def _check_dependencies(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"""
        self.librosa_available = False
        self.pydub_available = False
        self.noisereduce_available = False
        
        try:
            import librosa
            self.librosa_available = True
            logger.info("‚úÖ librosa available for audio processing")
        except ImportError:
            logger.warning("‚ö†Ô∏è librosa not available - limited audio processing")
        
        try:
            from pydub import AudioSegment
            self.pydub_available = True
            logger.info("‚úÖ pydub available for audio format conversion")
        except ImportError:
            logger.warning("‚ö†Ô∏è pydub not available - limited format support")
        
        try:
            import noisereduce as nr
            self.noisereduce_available = True
            logger.info("‚úÖ noisereduce available for noise reduction")
        except ImportError:
            logger.warning("‚ö†Ô∏è noisereduce not available - basic noise reduction only")
    
    async def enhance_audio(self, audio_file: str, **kwargs) -> str:
        """
        –£–ª—É—á—à–µ–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            str: –ü—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        """
        if not Path(audio_file).exists():
            raise FileNotFoundError(f"Audio file not found: {audio_file}")
        
        start_time = time.time()
        logger.info(f"üéµ Starting audio enhancement: {Path(audio_file).name}")
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ
        metadata = await self.analyze_audio(audio_file)
        logger.info(f"üìä Original audio: {metadata.duration:.1f}s, {metadata.sample_rate}Hz, {metadata.format.value}")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            enhanced_file = self._create_temp_filename(audio_file, "enhanced")
            
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            current_file = audio_file
            
            # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if self._needs_format_conversion(metadata):
                logger.info("üîÑ Converting audio format...")
                converted_file = await self._convert_audio_format(current_file, metadata)
                current_file = converted_file
            
            # 2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            if self.enable_volume_normalization:
                logger.info("üîä Normalizing volume...")
                normalized_file = await self._normalize_volume(current_file)
                current_file = normalized_file
            
            # 3. –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
            if self.enable_noise_reduction and self._needs_noise_reduction(metadata):
                logger.info("üîá Reducing noise...")
                denoised_file = await self._reduce_noise(current_file)
                current_file = denoised_file
            
            # 4. –£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ—á–∏
            if self.enable_speech_enhancement:
                logger.info("üó£Ô∏è Enhancing speech...")
                enhanced_speech_file = await self._enhance_speech(current_file)
                current_file = enhanced_speech_file
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
            if current_file != audio_file:
                shutil.copy2(current_file, enhanced_file)
            else:
                # –ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞, –∫–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                shutil.copy2(audio_file, enhanced_file)
            
            processing_time = time.time() - start_time
            logger.info(f"‚úÖ Audio enhancement completed in {processing_time:.1f}s: {enhanced_file}")
            
            return enhanced_file
            
        except Exception as e:
            logger.error(f"‚ùå Audio enhancement failed: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return audio_file
    
    async def analyze_audio(self, audio_file: str, **kwargs) -> AudioMetadata:
        """
        –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            AudioMetadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ
        """
        file_path = Path(audio_file)
        if not file_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_file}")
        
        start_time = time.time()
        
        try:
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–∞
            file_size = file_path.stat().st_size
            audio_format = self._detect_audio_format(file_path.suffix)
            
            # –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            if self.librosa_available:
                metadata = await self._analyze_with_librosa(audio_file, file_size, audio_format)
            else:
                metadata = await self._analyze_basic(audio_file, file_size, audio_format)
            
            analysis_duration = time.time() - start_time
            metadata.analysis_duration = analysis_duration
            
            logger.info(f"üìä Audio analysis completed: {metadata.quality_score:.2f} quality score")
            return metadata
            
        except Exception as e:
            logger.error(f"Audio analysis failed: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            return AudioMetadata(
                file_path=str(file_path),
                file_size=file_path.stat().st_size,
                duration=0.0,
                sample_rate=16000,
                channels=1,
                format=self._detect_audio_format(file_path.suffix),
                analysis_duration=time.time() - start_time
            )
    
    async def _analyze_with_librosa(self, audio_file: str, file_size: int, audio_format: AudioFormat) -> AudioMetadata:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å librosa"""
        import librosa
        import numpy as np
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
        y, sr = librosa.load(audio_file, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_metrics = self._calculate_quality_metrics(y, sr)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ—á–∏
        speech_segments = self._detect_speech_segments(y, sr)
        
        # –ê–Ω–∞–ª–∏–∑ —à—É–º–∞
        noise_level = self._estimate_noise_level(y)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
        overall_quality = self._determine_audio_quality(quality_metrics, noise_level)
        
        return AudioMetadata(
            file_path=audio_file,
            file_size=file_size,
            duration=duration,
            sample_rate=sr,
            channels=1 if len(y.shape) == 1 else y.shape[0],
            format=audio_format,
            overall_quality=overall_quality,
            quality_score=quality_metrics['overall_score'],
            snr_db=quality_metrics.get('snr_db'),
            speech_segments=speech_segments,
            total_speech_duration=sum(seg.duration for seg in speech_segments),
            background_noise_level=noise_level,
            needs_noise_reduction=noise_level > 0.3,
            needs_volume_normalization=quality_metrics['needs_volume_norm'],
            average_volume_db=quality_metrics.get('avg_volume_db'),
            peak_volume_db=quality_metrics.get('peak_volume_db')
        )
    
    async def _analyze_basic(self, audio_file: str, file_size: int, audio_format: AudioFormat) -> AudioMetadata:
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ librosa"""
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ pydub –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.pydub_available:
            from pydub import AudioSegment
            audio = AudioSegment.from_file(audio_file)
            
            return AudioMetadata(
                file_path=audio_file,
                file_size=file_size,
                duration=len(audio) / 1000.0,  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                sample_rate=audio.frame_rate,
                channels=audio.channels,
                format=audio_format,
                quality_score=0.7  # —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞
            )
        else:
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            return AudioMetadata(
                file_path=audio_file,
                file_size=file_size,
                duration=0.0,
                sample_rate=16000,
                channels=1,
                format=audio_format,
                quality_score=0.5
            )
    
    def _calculate_quality_metrics(self, y, sr) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ"""
        import numpy as np
        
        # RMS —ç–Ω–µ—Ä–≥–∏—è
        rms_energy = np.sqrt(np.mean(y**2))
        
        # Zero crossing rate
        zcr = np.mean(np.abs(np.diff(np.sign(y))))
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥
        try:
            import librosa
            spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
        except:
            spectral_centroid = 0.0
        
        # SNR –æ—Ü–µ–Ω–∫–∞
        signal_power = np.mean(y**2)
        noise_power = np.var(y - np.mean(y))
        snr_db = 10 * np.log10(signal_power / max(noise_power, 1e-10))
        
        # –ì—Ä–æ–º–∫–æ—Å—Ç—å –≤ dB
        avg_volume_db = 20 * np.log10(max(rms_energy, 1e-10))
        peak_volume_db = 20 * np.log10(max(np.max(np.abs(y)), 1e-10))
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_factors = [
            min(snr_db / 20.0, 1.0),  # SNR —Ñ–∞–∫—Ç–æ—Ä
            min(rms_energy * 10, 1.0),  # –≠–Ω–µ—Ä–≥–∏—è —Ñ–∞–∫—Ç–æ—Ä  
            1.0 - min(zcr, 1.0)  # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        ]
        overall_score = np.mean(quality_factors)
        
        return {
            'overall_score': float(overall_score),
            'rms_energy': float(rms_energy),
            'zcr': float(zcr),
            'spectral_centroid': float(spectral_centroid),
            'snr_db': float(snr_db),
            'avg_volume_db': float(avg_volume_db),
            'peak_volume_db': float(peak_volume_db),
            'needs_volume_norm': abs(avg_volume_db + 20) > 6  # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç -20dB
        }
    
    def _detect_speech_segments(self, y, sr):
        """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—á–∏"""
        from ..core.models.audio_metadata import SpeechSegment
        
        # –ü—Ä–æ—Å—Ç–æ–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–µ—Ä–≥–∏–∏
        frame_length = int(0.025 * sr)  # 25ms frames
        hop_length = int(0.01 * sr)     # 10ms hop
        
        # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Ñ—Ä–µ–π–º—ã
        frames = []
        for i in range(0, len(y) - frame_length, hop_length):
            frame = y[i:i + frame_length]
            energy = np.sum(frame ** 2)
            frames.append(energy)
        
        # –ü–æ—Ä–æ–≥–æ–≤–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è
        energy_threshold = np.percentile(frames, 75)  # 75-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
        
        segments = []
        in_speech = False
        start_time = 0
        
        for i, energy in enumerate(frames):
            time_point = i * hop_length / sr
            
            if energy > energy_threshold and not in_speech:
                # –ù–∞—á–∞–ª–æ —Ä–µ—á–∏
                in_speech = True
                start_time = time_point
            elif energy <= energy_threshold and in_speech:
                # –ö–æ–Ω–µ—Ü —Ä–µ—á–∏
                in_speech = False
                if time_point - start_time > 0.3:  # –ú–∏–Ω–∏–º—É–º 300ms
                    segments.append(SpeechSegment(
                        start_time=start_time,
                        end_time=time_point,
                        confidence=0.8
                    ))
        
        # –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        if in_speech:
            segments.append(SpeechSegment(
                start_time=start_time,
                end_time=len(y) / sr,
                confidence=0.8
            ))
        
        return segments
    
    def _estimate_noise_level(self, y) -> float:
        """–û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —à—É–º–∞"""
        import numpy as np
        
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ –∫–≤–∞–Ω—Ç–∏–ª–∏
        rms = np.sqrt(np.mean(y**2))
        noise_floor = np.percentile(np.abs(y), 10)  # 10-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –∫–∞–∫ —à—É–º
        
        if rms > 0:
            noise_ratio = noise_floor / rms
        else:
            noise_ratio = 1.0
        
        return min(noise_ratio, 1.0)
    
    def _determine_audio_quality(self, quality_metrics: Dict, noise_level: float) -> AudioQuality:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —É—Ä–æ–≤–Ω—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ"""
        score = quality_metrics['overall_score']
        snr = quality_metrics.get('snr_db', 0)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—É–º–∞ –∏ SNR
        adjusted_score = score * (1 - noise_level) * min(snr / 20.0, 1.0)
        
        if adjusted_score >= 0.9:
            return AudioQuality.EXCELLENT
        elif adjusted_score >= 0.7:
            return AudioQuality.GOOD
        elif adjusted_score >= 0.5:
            return AudioQuality.FAIR
        elif adjusted_score >= 0.3:
            return AudioQuality.POOR
        else:
            return AudioQuality.VERY_POOR
    
    def _detect_audio_format(self, suffix: str) -> AudioFormat:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –∞—É–¥–∏–æ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é"""
        suffix_lower = suffix.lower().lstrip('.')
        
        format_map = {
            'wav': AudioFormat.WAV,
            'mp3': AudioFormat.MP3,
            'm4a': AudioFormat.M4A,
            'flac': AudioFormat.FLAC,
            'ogg': AudioFormat.OGG,
            'webm': AudioFormat.WEBM
        }
        
        return format_map.get(suffix_lower, AudioFormat.UNKNOWN)
    
    def _needs_format_conversion(self, metadata: AudioMetadata) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞"""
        needs_conversion = (
            metadata.sample_rate != self.target_sample_rate or
            (self.convert_to_mono and metadata.channels > 1) or
            metadata.format not in [AudioFormat.WAV, AudioFormat.FLAC]
        )
        
        return needs_conversion
    
    def _needs_noise_reduction(self, metadata: AudioMetadata) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è"""
        return (
            metadata.background_noise_level > 0.2 or
            metadata.overall_quality in [AudioQuality.POOR, AudioQuality.VERY_POOR]
        )
    
    def _create_temp_filename(self, original_file: str, suffix: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–º–µ–Ω–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        original_path = Path(original_file)
        temp_name = f"{original_path.stem}_{suffix}_{int(time.time())}.wav"
        return str(self.temp_dir / temp_name)
    
    async def _convert_audio_format(self, audio_file: str, metadata: AudioMetadata) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        output_file = self._create_temp_filename(audio_file, "converted")
        
        if self.librosa_available:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ librosa
            import librosa
            import soundfile as sf
            
            y, sr = librosa.load(audio_file, sr=self.target_sample_rate, mono=self.convert_to_mono)
            sf.write(output_file, y, sr)
            
        elif self.pydub_available:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ pydub
            from pydub import AudioSegment
            
            audio = AudioSegment.from_file(audio_file)
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            if audio.frame_rate != self.target_sample_rate:
                audio = audio.set_frame_rate(self.target_sample_rate)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–Ω–æ
            if self.convert_to_mono and audio.channels > 1:
                audio = audio.set_channels(1)
            
            # –≠–∫—Å–ø–æ—Ä—Ç –≤ WAV
            audio.export(output_file, format="wav")
        
        else:
            # –ë–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫ - –∫–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
            shutil.copy2(audio_file, output_file)
        
        return output_file
    
    async def _normalize_volume(self, audio_file: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏"""
        output_file = self._create_temp_filename(audio_file, "normalized")
        
        if self.librosa_available:
            import librosa
            import soundfile as sf
            import numpy as np
            
            y, sr = librosa.load(audio_file, sr=None)
            
            # RMS –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ -20dB
            current_rms = np.sqrt(np.mean(y**2))
            if current_rms > 0:
                target_rms = 0.1  # –ü—Ä–∏–º–µ—Ä–Ω–æ -20dB
                y_normalized = y * (target_rms / current_rms)
                
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∏–∫–æ–≤
                y_normalized = np.clip(y_normalized, -1.0, 1.0)
            else:
                y_normalized = y
            
            sf.write(output_file, y_normalized, sr)
            
        elif self.pydub_available:
            from pydub import AudioSegment
            
            audio = AudioSegment.from_file(audio_file)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ pydub
            normalized_audio = audio.normalize()
            
            # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –¥–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
            normalized_audio = normalized_audio - 6  # -6dB –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞
            
            normalized_audio.export(output_file, format="wav")
        
        else:
            shutil.copy2(audio_file, output_file)
        
        return output_file
    
    async def _reduce_noise(self, audio_file: str) -> str:
        """–®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ"""
        output_file = self._create_temp_filename(audio_file, "denoised")
        
        if self.noisereduce_available and self.librosa_available:
            import noisereduce as nr
            import librosa
            import soundfile as sf
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
            y, sr = librosa.load(audio_file, sr=None)
            
            # –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
            y_denoised = nr.reduce_noise(y=y, sr=sr, stationary=False)
            
            sf.write(output_file, y_denoised, sr)
            
        else:
            # –ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
            await self._simple_noise_reduction(audio_file, output_file)
        
        return output_file
    
    async def _simple_noise_reduction(self, input_file: str, output_file: str):
        """–ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –±–µ–∑ noisereduce"""
        if self.librosa_available:
            import librosa
            import soundfile as sf
            import numpy as np
            
            y, sr = librosa.load(input_file, sr=None)
            
            # –ü—Ä–æ—Å—Ç–æ–π high-pass —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —à—É–º–∞
            from scipy import signal
            
            # High-pass —Ñ–∏–ª—å—Ç—Ä —Å —á–∞—Å—Ç–æ—Ç–æ–π —Å—Ä–µ–∑–∞ 80Hz
            sos = signal.butter(4, 80, btype='high', fs=sr, output='sos')
            y_filtered = signal.sosfilt(sos, y)
            
            sf.write(output_file, y_filtered, sr)
        else:
            # –ë–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            shutil.copy2(input_file, output_file)
    
    async def _enhance_speech(self, audio_file: str) -> str:
        """–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ—á–∏"""
        output_file = self._create_temp_filename(audio_file, "enhanced")
        
        if self.librosa_available:
            import librosa
            import soundfile as sf
            import numpy as np
            
            y, sr = librosa.load(audio_file, sr=None)
            
            # –ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —á–∞—Å—Ç–æ—Ç (300Hz - 3400Hz)
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º—è–≥–∫–æ–≥–æ —ç–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞
            y_enhanced = self._apply_speech_eq(y, sr)
            
            sf.write(output_file, y_enhanced, sr)
        else:
            shutil.copy2(audio_file, output_file)
        
        return output_file
    
    def _apply_speech_eq(self, y, sr):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ—á–∏"""
        try:
            from scipy import signal
            import numpy as np
            
            # –õ–µ–≥–∫–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö —á–∞—Å—Ç–æ—Ç (—Ä–µ—á–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω)
            # Band-pass —Ñ–∏–ª—å—Ç—Ä 300Hz - 3400Hz —Å –Ω–µ–±–æ–ª—å—à–∏–º —É—Å–∏–ª–µ–Ω–∏–µ–º
            
            # –î–∏–∑–∞–π–Ω —Ñ–∏–ª—å—Ç—Ä–∞
            nyquist = sr / 2
            low_freq = 300 / nyquist
            high_freq = min(3400 / nyquist, 0.99)
            
            b, a = signal.butter(2, [low_freq, high_freq], btype='band')
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ —Å –Ω–µ–±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º
            y_filtered = signal.filtfilt(b, a, y)
            
            # –°–º–µ—à–∏–≤–∞–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º (80% –æ—Ä–∏–≥–∏–Ω–∞–ª, 20% —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π)
            y_enhanced = 0.8 * y + 0.2 * y_filtered
            
            return y_enhanced
            
        except Exception as e:
            logger.warning(f"Speech EQ failed: {e}")
            return y
    
    def reduce_noise(
        self, 
        audio_data: Any, 
        sample_rate: int,
        reduction_strength: float = 0.8
    ) -> Any:
        """
        –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
        Noise reduction
        
        Args:
            audio_data: –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ (numpy array)
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            reduction_strength: –°–∏–ª–∞ –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è —à—É–º–∞ (0-1)
            
        Returns:
            Any: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            import numpy as np
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if audio_data is None:
                raise ValueError("Audio data is None")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy array –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data)
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ noisereduce –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            if self.noisereduce_available:
                import noisereduce as nr
                return nr.reduce_noise(
                    y=audio_data, 
                    sr=sample_rate, 
                    stationary=False,
                    prop_decrease=reduction_strength
                )
            
            # –ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
            return self._apply_simple_noise_reduction(audio_data, sample_rate, reduction_strength)
            
        except Exception as e:
            logger.error(f"Noise reduction failed: {e}")
            return audio_data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def normalize_volume(self, audio_data: Any, target_db: float = -20.0) -> Any:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        Volume normalization
        
        Args:
            audio_data: –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
            target_db: –¶–µ–ª–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å –≤ –¥–ë
            
        Returns:
            Any: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            import numpy as np
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if audio_data is None:
                raise ValueError("Audio data is None")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy array –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data)
            
            # –†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–µ–≥–æ RMS
            current_rms = np.sqrt(np.mean(audio_data**2))
            
            if current_rms == 0:
                return audio_data  # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º —Å —Ç–∏—à–∏–Ω–æ–π
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ target_db –≤ –ª–∏–Ω–µ–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            target_linear = 10**(target_db / 20.0)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            normalization_factor = target_linear / current_rms
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            normalized_audio = audio_data * normalization_factor
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∏–∫–æ–≤ (–∏–∑–±–µ–∂–∞–Ω–∏–µ –∫–ª–∏–ø–ø–∏–Ω–≥–∞)
            max_val = np.max(np.abs(normalized_audio))
            if max_val > 1.0:
                normalized_audio = normalized_audio / max_val * 0.99
            
            return normalized_audio
            
        except Exception as e:
            logger.error(f"Volume normalization failed: {e}")
            return audio_data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def resample_audio(
        self, 
        audio_data: Any, 
        original_sr: int, 
        target_sr: int
    ) -> Any:
        """
        –†–µ—Å—ç–º–ø–ª–∏–Ω–≥ –∞—É–¥–∏–æ
        Resample audio to target sample rate
        
        Args:
            audio_data: –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
            original_sr: –ò—Å—Ö–æ–¥–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
            target_sr: –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞
            
        Returns:
            Any: –†–µ—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            import numpy as np
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if audio_data is None:
                raise ValueError("Audio data is None")
            
            if original_sr == target_sr:
                return audio_data  # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy array –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data)
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ librosa –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥–∞
            if self.librosa_available:
                import librosa
                return librosa.resample(audio_data, orig_sr=original_sr, target_sr=target_sr)
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥ —á–µ—Ä–µ–∑ scipy
            try:
                from scipy import signal
                
                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—ç–º–ø–ª–æ–≤
                num_samples = int(len(audio_data) * target_sr / original_sr)
                
                # –†–µ—Å—ç–º–ø–ª–∏–Ω–≥
                resampled = signal.resample(audio_data, num_samples)
                
                return resampled
                
            except ImportError:
                # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ª–∏–Ω–µ–π–Ω—ã–π —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥
                return self._simple_resample(audio_data, original_sr, target_sr)
                
        except Exception as e:
            logger.error(f"Audio resampling failed: {e}")
            return audio_data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _apply_simple_noise_reduction(self, audio_data, sample_rate: int, strength: float):
        """
        –ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –±–µ–∑ noisereduce
        Simple noise reduction without noisereduce library
        """
        try:
            import numpy as np
            
            # High-pass —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —à—É–º–∞
            try:
                from scipy import signal
                
                # –ü–æ—Ä–æ–≥–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏–ª—ã
                cutoff_freq = 50 + (strength * 80)  # –æ—Ç 50–ì—Ü –¥–æ 130–ì—Ü
                
                # High-pass —Ñ–∏–ª—å—Ç—Ä
                sos = signal.butter(4, cutoff_freq, btype='high', fs=sample_rate, output='sos')
                filtered = signal.sosfilt(sos, audio_data)
                
                # –°–º–µ—à–∏–≤–∞–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º
                mix_factor = 0.3 + (strength * 0.5)  # –æ—Ç 30% –¥–æ 80% —Ñ–∏–ª—å—Ç—Ä–∞
                result = (1 - mix_factor) * audio_data + mix_factor * filtered
                
                return result
                
            except ImportError:
                # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
                window_size = max(3, int(sample_rate * 0.001))  # 1ms –æ–∫–Ω–æ
                smoothed = np.convolve(audio_data, np.ones(window_size)/window_size, mode='same')
                return (1 - strength) * audio_data + strength * smoothed
                
        except Exception as e:
            logger.error(f"Simple noise reduction failed: {e}")
            return audio_data
    
    def _simple_resample(self, audio_data, original_sr: int, target_sr: int):
        """
        –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ª–∏–Ω–µ–π–Ω—ã–π —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥
        Simplest linear resampling
        """
        try:
            import numpy as np
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –¥–ª–∏–Ω—ã
            original_length = len(audio_data)
            new_length = int(original_length * target_sr / original_sr)
            
            # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
            original_indices = np.arange(original_length)
            new_indices = np.linspace(0, original_length - 1, new_length)
            
            # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
            resampled = np.interp(new_indices, original_indices, audio_data)
            
            return resampled
            
        except Exception as e:
            logger.error(f"Simple resampling failed: {e}")
            return audio_data